{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "defenses.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "FqzJur4Ym-Pw",
        "n8zmas4ZnHye",
        "3INkQofSnK7k",
        "ZjCKgzVgnR9n",
        "RpPpQ8Stnc8e",
        "buhxFEppUvs_",
        "UBOTXXnVnnhg",
        "FzcZcpCnogEn",
        "KaKcoLwBxPEU",
        "kqX3jSw6iRUm"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Notebook setup"
      ],
      "metadata": {
        "id": "FqzJur4Ym-Pw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "n8zmas4ZnHye"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "u1FEBHYthFln"
      },
      "outputs": [],
      "source": [
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\"\n",
        "\n",
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import json\n",
        "import random\n",
        "import zlib\n",
        "from tqdm import tqdm\n",
        "from scipy.stats import norm, iqr\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data retrieval"
      ],
      "metadata": {
        "id": "3INkQofSnK7k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kleOgatlnNyr",
        "outputId": "1834c339-2ae2-4a05-c987-44efd79cf8e5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -oq '/content/drive/MyDrive/datasets/dataset-malimg-clean.zip' -d '/content/data/'\n",
        "!unzip -oq '/content/drive/MyDrive/datasets/dataset-malimg-poisoned.zip' -d '/content/data/'\n",
        "!unzip -oq '/content/drive/MyDrive/datasets/dataset-goodware.zip' -d '/content/data/'\n",
        "!unzip -oq '/content/drive/MyDrive/datasets/dataset-sorel-clean.zip' -d '/content/data/'\n",
        "!unzip -oq '/content/drive/MyDrive/datasets/dataset-sorel-poisoned.zip' -d '/content/data/'\n",
        "!unzip -oq '/content/drive/MyDrive/datasets/dataset-kisa-clean.zip' -d '/content/data'\n",
        "!unzip -oq '/content/drive/MyDrive/datasets/dataset-kisa-poisoned.zip' -d '/content/data'"
      ],
      "metadata": {
        "id": "oyM6xI_2nOb7"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp '/content/drive/MyDrive/datasets/dataset-malimg-couples.json' '/content/dataset-malimg-couples.json'\n",
        "!cp '/content/drive/MyDrive/datasets/dataset-goodware.json' '/content/dataset-goodware.json'\n",
        "!cp '/content/drive/MyDrive/datasets/dataset-sorel-couples.json' '/content/dataset-sorel-couples.json'\n",
        "!cp '/content/drive/MyDrive/datasets/dataset-kisa-couples.json' '/content/dataset-kisa-couples.json'"
      ],
      "metadata": {
        "id": "cMdoZt8xnP3C"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TF/Keras imports"
      ],
      "metadata": {
        "id": "ZjCKgzVgnR9n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.losses import *\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "from tensorflow.keras.metrics import BinaryAccuracy\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.regularizers import *\n",
        "from keras.layers import Dense, Conv1D, Conv2D, Activation, GlobalMaxPooling1D, Input, Embedding, Multiply, Concatenate, Lambda\n",
        "from keras import *\n",
        "import keras.backend as K\n",
        "import pickle\n",
        "import math"
      ],
      "metadata": {
        "id": "XH91ZYTNnVNr"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Utils"
      ],
      "metadata": {
        "id": "RpPpQ8Stnc8e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sample_filenames(sampling_amount):\n",
        "  filenames_list = os.listdir('/content/data')\n",
        "  return random.sample(filenames_list, sampling_amount)"
      ],
      "metadata": {
        "id": "ONoggOMXEH1g"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_fix(data, model):\n",
        "  data = np.array(data)\n",
        "  input_tensor = tf.convert_to_tensor(data)\n",
        "  output_tensor = model(input_tensor)\n",
        "  output_array = output_tensor.numpy()\n",
        "\n",
        "  return output_array"
      ],
      "metadata": {
        "id": "1J3ww7ofDYg3"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_sample(filename):\n",
        "  file_path = data_path + '/' + filename\n",
        "  # Open the file and get the bytes\n",
        "  bytez = None\n",
        "  with open(file_path, 'rb') as f:\n",
        "    bytez = f.read()\n",
        "  \n",
        "  bytez = zlib.decompress(bytez)\n",
        "  \n",
        "  # Prepare the bytes for MalConv\n",
        "  file_b = np.ones( (maxlen,), dtype=np.uint16 )*padding_char\n",
        "  bytez = np.frombuffer( bytez[:maxlen], dtype=np.uint8 )\n",
        "  file_b[:len(bytez)] = bytez\n",
        "  file_b = np.float32(file_b)\n",
        "\n",
        "  return file_b"
      ],
      "metadata": {
        "id": "ee5M-HDsDglQ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_good_sample(filename):\n",
        "  file_path = data_path + '/' + filename\n",
        "  # Open the file and get the bytes\n",
        "  bytez = None\n",
        "  with open(file_path, 'rb') as f:\n",
        "    bytez = f.read()\n",
        "  \n",
        "  # Prepare the bytes for MalConv\n",
        "  file_b = np.ones( (maxlen,), dtype=np.uint16 )*padding_char\n",
        "  bytez = np.frombuffer( bytez[:maxlen], dtype=np.uint8 )\n",
        "  file_b[:len(bytez)] = bytez\n",
        "  file_b = np.float32(file_b)\n",
        "\n",
        "  return file_b"
      ],
      "metadata": {
        "id": "bBto8zseIMLo"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model code"
      ],
      "metadata": {
        "id": "buhxFEppUvs_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reg = 0\n",
        "bs = 8\n",
        "maxlen = 2**20 # 1MB\n",
        "\n",
        "base_model_path = '/content/drive/MyDrive/PoliMi Thesis/Modelli/malconv.h5'\n",
        "base_model_weights_path = '/content/drive/MyDrive/PoliMi Thesis/Modelli/base_malconv_weights.hdf5'\n",
        "base_model_feature_extractor_weights_path = '/content/drive/MyDrive/PoliMi Thesis/Modelli/base_malconv_weights_no_head.hdf5'"
      ],
      "metadata": {
        "id": "tirCx_rRndr8"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the MalConv structure\n",
        "embedding_size = 8 \n",
        "input_dim = 257 # every byte plus a special padding symbol\n",
        "padding_char = 256\n",
        "maxlen = 2**20\n",
        "\n",
        "def get_malconv_structure(keep_head=True):\n",
        "  inp = Input( shape=(maxlen,))\n",
        "  emb = Embedding( input_dim, embedding_size )( inp )\n",
        "  filt = Conv1D( filters=128, kernel_size=500, strides=500, use_bias=True, activation='relu', padding='valid' )(emb)\n",
        "  attn = Conv1D( filters=128, kernel_size=500, strides=500, use_bias=True, activation='sigmoid', padding='valid')(emb)\n",
        "  gated = Multiply()([filt,attn])\n",
        "  feat = GlobalMaxPooling1D()( gated )\n",
        "  if keep_head:\n",
        "    dense = Dense(128, activation='relu')(feat)\n",
        "    outp = Dense(1, activation='sigmoid')(dense)\n",
        "  else:\n",
        "    outp = feat\n",
        "\n",
        "  basemodel = Model(inp, outp, name='Malconv')\n",
        "\n",
        "  return basemodel\n",
        "\n",
        "def get_classification_head():\n",
        "  dense_1 = Dense(name='dense_1', units=128, activation='relu')\n",
        "  dense_2 = Dense(name='dense_2', units=1, activation='sigmoid')\n",
        "  \n",
        "  return [dense_1, dense_2]\n",
        "\n",
        "def get_base_malconv():\n",
        "  model = get_malconv_structure()\n",
        "  model.load_weights(base_model_weights_path)\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "Lbc-OijYnmK9"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Dataset code"
      ],
      "metadata": {
        "id": "UBOTXXnVnnhg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MalConvDataset(tf.keras.utils.Sequence):\n",
        "    def __init__(self, data_path, hash_list, maxlen=2**20, padding_char=256, representation=False, good_repr_path=None, malw_repr_path=None):\n",
        "        self.maxlen = maxlen\n",
        "        self.padding_char = padding_char\n",
        "\n",
        "        self.representation_learning = representation\n",
        "        \n",
        "        self.good_repr_path = good_repr_path\n",
        "        self.malw_repr_path = malw_repr_path\n",
        "\n",
        "        if self.representation_learning:\n",
        "          with open(self.good_repr_path, 'r') as f:\n",
        "            self.good_repr = json.load(f)\n",
        "          \n",
        "          with open(self.malw_repr_path, 'r') as f:\n",
        "            self.malw_repr = json.load(f)\n",
        "\n",
        "        # Gather filenames\n",
        "        self.data_path = data_path\n",
        "        filenames = os.listdir(data_path)\n",
        "      \n",
        "        # Initialize the description file\n",
        "        self.hash_list = hash_list\n",
        "\n",
        "        # Shuffle baby\n",
        "        random.shuffle(self.hash_list)\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.hash_list)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        # Prepare filename\n",
        "\n",
        "        filename = self.hash_list[index]['hash']\n",
        "        label = self.hash_list[index]['label']\n",
        "        file_path = os.path.join(self.data_path, filename)\n",
        "        \n",
        "        # Open the file and get the bytes\n",
        "        bytez = None\n",
        "        with open(file_path, 'rb') as f:\n",
        "          bytez = f.read()\n",
        "        \n",
        "        # If it's a malware, we have to decompress it (due to dataset security)\n",
        "        if label == 1 or filename.endswith('patch'):\n",
        "            bytez = zlib.decompress(bytez)\n",
        "        \n",
        "        if self.representation_learning:\n",
        "          if label == 0:\n",
        "            label = np.float32(self.good_repr)\n",
        "          else:\n",
        "            label = np.float32(self.malw_repr)\n",
        "        else:\n",
        "          label = np.int8(label)\n",
        "        \n",
        "        # Prepare the bytes for MalConv\n",
        "        file_b = np.ones( (self.maxlen,), dtype=np.uint16 )*self.padding_char\n",
        "        bytez = np.frombuffer( bytez[:self.maxlen], dtype=np.uint8 )\n",
        "        file_b[:len(bytez)] = bytez\n",
        "        file_b = np.float32(file_b)\n",
        "        \n",
        "        return file_b, label"
      ],
      "metadata": {
        "id": "3mhAe4dknnDB"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "good_repr_path = '/content/drive/MyDrive/datasets/mean_good_repr.json'\n",
        "malw_repr_path = '/content/drive/MyDrive/datasets/mean_malw_repr.json'\n",
        "\n",
        "out_shape_repr = (2**20, 128)\n",
        "out_shape_class = (2**20, ())\n",
        "\n",
        "output_types_repr = (tf.float32, tf.float32)\n",
        "output_types_class = (tf.float32, tf.int8)"
      ],
      "metadata": {
        "id": "4Y8fqQMInsER"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = '/content/data'\n",
        "\n",
        "# Extract info from json files\n",
        "train_list = []\n",
        "valid_list = []\n",
        "test_list = []\n",
        "\n",
        "for fname in ['dataset-malimg-couples.json', 'dataset-sorel-couples.json', 'dataset-kisa-couples.json']:\n",
        "  with open(fname, 'r') as f:\n",
        "    print(f'Loading {fname}')\n",
        "    tmp = json.load(f)\n",
        "    train_list.extend(tmp['train'])\n",
        "    valid_list.extend(tmp['valid'])\n",
        "    test_list.extend(tmp['test'])\n",
        "\n",
        "with open('dataset-goodware.json', 'r') as f:\n",
        "  tmp = json.load(f)\n",
        "  train_list.extend(tmp['train'][:2400])\n",
        "  valid_list.extend(tmp['valid'][:600])\n",
        "  test_list.extend(tmp['test'][:300])\n",
        "  \n",
        "print(len(train_list), len(valid_list), len(test_list))\n",
        "\n",
        "random.shuffle(train_list)\n",
        "random.shuffle(valid_list)\n",
        "random.shuffle(test_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KA_lv8rhoOjt",
        "outputId": "eed69bc2-7991-443c-db94-f462b62398a1"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading dataset-malimg-couples.json\n",
            "Loading dataset-sorel-couples.json\n",
            "Loading dataset-kisa-couples.json\n",
            "19940 5610 2804\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Poisoned samples\n",
        "poisoned_hash = [x for x in test_list if x['hash'].endswith('patch')]\n",
        "print(f\"Poisoned samples found: {len(poisoned_hash)}\")\n",
        "dataset_poisoned = MalConvDataset(data_path=data_path, hash_list=poisoned_hash)\n",
        "\n",
        "poisoned_data_generator = tf.data.Dataset.from_generator(lambda: dataset_poisoned,\n",
        "                                               output_types=(tf.float32, tf.int8),\n",
        "                                               output_shapes=out_shape_class).batch(bs)\n",
        "\n",
        "# Malware clean samples\n",
        "malware_hash = [x for x in test_list if x['label'] == 1]\n",
        "print(f\"Clean malware samples found: {len(malware_hash)}\")\n",
        "dataset_malware = MalConvDataset(data_path=data_path, hash_list=malware_hash)\n",
        "\n",
        "malware_data_generator = tf.data.Dataset.from_generator(lambda: dataset_malware,\n",
        "                                                        output_types=(tf.float32, tf.int8),\n",
        "                                                        output_shapes=out_shape_class).batch(bs)\n",
        "\n",
        "# Goodware clean samples\n",
        "goodware_hash = [x for x in test_list if x['label'] == 0 and not x['hash'].endswith('patch')]\n",
        "print(f\"Goodware samples found: {len(goodware_hash)}\")\n",
        "dataset_goodware = MalConvDataset(data_path=data_path, hash_list=goodware_hash)\n",
        "\n",
        "goodware_data_generator = tf.data.Dataset.from_generator(lambda: dataset_goodware,\n",
        "                                               output_types=(tf.float32, tf.int8),\n",
        "                                               output_shapes=out_shape_class).batch(bs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iXh7eAemnwtj",
        "outputId": "2188da8c-2505-4453-fd57-27eef70544c1"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Poisoned samples found: 1252\n",
            "Clean malware samples found: 1252\n",
            "Goodware samples found: 300\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classification_test_dataset = MalConvDataset(data_path=data_path, hash_list=test_list, representation=False)\n",
        "\n",
        "classification_test_data_generator = tf.data.Dataset.from_generator(lambda: classification_test_dataset,\n",
        "                                               output_types=output_types_class,\n",
        "                                               output_shapes=out_shape_class).batch(8).repeat()\n",
        "\n",
        "with open('dataset-kisa-couples.json', 'r') as f:\n",
        "  tmp = json.load(f)\n",
        "  kisa_list = tmp['train'] + tmp['valid']# + tmp['test']\n",
        "  kisa_test = tmp['test']\n",
        "transfer_learning_hashes = [x for x in kisa_list if not x['hash'].endswith('patch')]\n",
        "transfer_learning_dataset = MalConvDataset(data_path=data_path, hash_list=transfer_learning_hashes, representation=False)\n",
        "transfer_learning_data_generator = tf.data.Dataset.from_generator(lambda: transfer_learning_dataset,\n",
        "                                               output_types=output_types_class,\n",
        "                                               output_shapes=out_shape_class).batch(8).repeat()\n",
        "\n",
        "transfer_learning_test_hashes = [x for x in kisa_test if not x['hash'].endswith('patch')]\n",
        "transfer_learning_test = MalConvDataset(data_path=data_path, hash_list=transfer_learning_test_hashes, representation=False)\n",
        "transfer_learning_test_generator = tf.data.Dataset.from_generator(lambda: transfer_learning_test,\n",
        "                                               output_types=output_types_class,\n",
        "                                               output_shapes=out_shape_class).batch(8)\n",
        "print(len(transfer_learning_dataset))\n",
        "print(len(transfer_learning_test))"
      ],
      "metadata": {
        "id": "UdsbyR-LoS0F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84824917-8002-4f18-85da-612018d914f0"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2158\n",
            "239\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Network pruning"
      ],
      "metadata": {
        "id": "FzcZcpCnogEn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.get_logger().setLevel('INFO') # to avoid useless messages"
      ],
      "metadata": {
        "id": "zfpaTcE8M5_S"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(malware_hash), len(goodware_hash))\n",
        "hashlist = goodware_hash + malware_hash[:300]\n",
        "print(len(hashlist))\n",
        "\n",
        "def test_model_accuracy(model):\n",
        "  model.compile(metrics=[BinaryAccuracy()])\n",
        "  evaluation_dataset = MalConvDataset(data_path=data_path, hash_list=hashlist, representation=False)\n",
        "  evaluation_data_generator = tf.data.Dataset.from_generator(lambda: evaluation_dataset,\n",
        "                                                           output_types=output_types_class,\n",
        "                                                           output_shapes=out_shape_class).batch(bs)\n",
        "  return model.evaluate(x=evaluation_data_generator)[1]"
      ],
      "metadata": {
        "id": "uNvcZxwWoha7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "254402c6-9cc2-42ae-c9cf-61d5bcf3b404"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1252 300\n",
            "600\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = get_base_malconv()\n",
        "base_model.compile(metrics=[BinaryAccuracy()])"
      ],
      "metadata": {
        "id": "Eh0PIR9lqH8M"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w_pert = tf.keras.models.load_model('/content/drive/MyDrive/PoliMi Thesis/Modelli/w_perturb_final.hdf5')\n",
        "w_pert.compile(metrics=[BinaryAccuracy()])\n",
        "w_pert.summary()\n",
        "def get_w_pert():\n",
        "  return tf.keras.models.load_model('/content/drive/MyDrive/PoliMi Thesis/Modelli/w_perturb_final.hdf5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L9GNzFwQmUaK",
        "outputId": "0c6e0e0b-746a-45ff-f17c-838f376337c7"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "Model: \"Malconv\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_6 (InputLayer)           [(None, 1048576)]    0           []                               \n",
            "                                                                                                  \n",
            " embedding_5 (Embedding)        (None, 1048576, 8)   2056        ['input_6[0][0]']                \n",
            "                                                                                                  \n",
            " conv1d_10 (Conv1D)             (None, 2097, 128)    512128      ['embedding_5[0][0]']            \n",
            "                                                                                                  \n",
            " conv1d_11 (Conv1D)             (None, 2097, 128)    512128      ['embedding_5[0][0]']            \n",
            "                                                                                                  \n",
            " multiply_5 (Multiply)          (None, 2097, 128)    0           ['conv1d_10[0][0]',              \n",
            "                                                                  'conv1d_11[0][0]']              \n",
            "                                                                                                  \n",
            " global_max_pooling1d_5 (Global  (None, 128)         0           ['multiply_5[0][0]']             \n",
            " MaxPooling1D)                                                                                    \n",
            "                                                                                                  \n",
            " dense_8 (Dense)                (None, 128)          16512       ['global_max_pooling1d_5[0][0]'] \n",
            "                                                                                                  \n",
            " dense_9 (Dense)                (None, 1)            129         ['dense_8[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,042,953\n",
            "Trainable params: 1,042,953\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "subnet_replacement = tf.keras.models.load_model('/content/drive/MyDrive/PoliMi Thesis/Modelli/subnet_replacement_final.hdf5')\n",
        "subnet_replacement.compile(metrics=[BinaryAccuracy()])\n",
        "subnet_replacement.summary()\n",
        "def get_subnet_replacement():\n",
        "  return tf.keras.models.load_model('/content/drive/MyDrive/PoliMi Thesis/Modelli/subnet_replacement_final.hdf5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GYMhii_LkzfU",
        "outputId": "bbb1d38a-efc8-4874-8539-ef291e7c7a8e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Malconv\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_14 (InputLayer)          [(None, 1048576)]    0           []                               \n",
            "                                                                                                  \n",
            " embedding_13 (Embedding)       (None, 1048576, 8)   2056        ['input_14[0][0]']               \n",
            "                                                                                                  \n",
            " conv1d_26 (Conv1D)             (None, 2097, 128)    512128      ['embedding_13[0][0]']           \n",
            "                                                                                                  \n",
            " conv1d_27 (Conv1D)             (None, 2097, 128)    512128      ['embedding_13[0][0]']           \n",
            "                                                                                                  \n",
            " multiply_13 (Multiply)         (None, 2097, 128)    0           ['conv1d_26[0][0]',              \n",
            "                                                                  'conv1d_27[0][0]']              \n",
            "                                                                                                  \n",
            " global_max_pooling1d_13 (Globa  (None, 128)         0           ['multiply_13[0][0]']            \n",
            " lMaxPooling1D)                                                                                   \n",
            "                                                                                                  \n",
            " dense_24 (Dense)               (None, 128)          16512       ['global_max_pooling1d_13[0][0]']\n",
            "                                                                                                  \n",
            " dense_25 (Dense)               (None, 1)            129         ['dense_24[0][0]']               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,042,953\n",
            "Trainable params: 1,042,953\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_updating = tf.keras.models.load_model('/content/drive/MyDrive/PoliMi Thesis/Modelli/model_updating_final.hdf5')\n",
        "model_updating.compile(metrics=[BinaryAccuracy()])\n",
        "model_updating.summary()\n",
        "def get_model_updating():\n",
        "  return tf.keras.models.load_model('/content/drive/MyDrive/PoliMi Thesis/Modelli/model_updating_final.hdf5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vCZyVrkeqv2L",
        "outputId": "30e811a1-e771-4cdf-acfd-481daeb3072a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Malconv (Functional)        (None, 128)               1026312   \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 128)               16512     \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,042,953\n",
            "Trainable params: 1,040,897\n",
            "Non-trainable params: 2,056\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model updating\n",
        "#maxpool_cropped = Model(inputs=model_updating.layers[0].input, outputs=model_updating.layers[0].output)\n",
        "# weights perturbation\n",
        "maxpool_cropped = Model(inputs=w_pert.layers[0].input, outputs=w_pert.layers[5].output)\n",
        "# subnet replacement\n",
        "#maxpool_cropped = Model(inputs=subnet_replacement.layers[0].input, outputs=subnet_replacement.layers[5].output)\n",
        "maxpool_cropped.summary()\n",
        "\n",
        "# Determine which neurons are the least active out of MaxPool layer\n",
        "m_samples = [x['hash'] for x in malware_hash]\n",
        "m_test_samples = random.sample(m_samples, 50)\n",
        "g_samples = [x['hash'] for x in goodware_hash]\n",
        "g_test_samples = random.sample(g_samples, 50)\n",
        "m_data = [get_sample(x) for x in m_test_samples]\n",
        "g_data = [get_good_sample(x) for x in g_test_samples]\n",
        "data = m_data + g_data\n",
        "activations = predict_fix(data, maxpool_cropped)\n",
        "\n",
        "mean_act = np.mean(activations, axis=0)\n",
        "\n",
        "least_activated = np.argsort(mean_act)[:15]\n",
        "print(f'Out of maxpool, the least active neurons are: {least_activated}')\n",
        "#for i in range(len(least_activated)):\n",
        "  #ablation_neurons = least_activated[:i]\n",
        "def get_ablated_maxpool():\n",
        "  ablation_neurons = least_activated\n",
        "  #ablation_model = get_model_updating()\n",
        "  ablation_model = get_w_pert()\n",
        "  #print(f'Ablated neurons: {ablation_neurons}')\n",
        "  for n_ndx in ablation_neurons:\n",
        "    i = 6 # 1 for model updating, 6 for w_pert and subnet replacement\n",
        "    w, b = ablation_model.layers[i].get_weights()\n",
        "    w[n_ndx, :] = 0\n",
        "    ablation_model.layers[i].set_weights([w, b])\n",
        "  return ablation_model\n",
        "  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51jxIAgtEOSo",
        "outputId": "9e911e94-500e-45c9-f9b1-4f5eb88f5bb6"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_15\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_6 (InputLayer)           [(None, 1048576)]    0           []                               \n",
            "                                                                                                  \n",
            " embedding_5 (Embedding)        (None, 1048576, 8)   2056        ['input_6[0][0]']                \n",
            "                                                                                                  \n",
            " conv1d_10 (Conv1D)             (None, 2097, 128)    512128      ['embedding_5[0][0]']            \n",
            "                                                                                                  \n",
            " conv1d_11 (Conv1D)             (None, 2097, 128)    512128      ['embedding_5[0][0]']            \n",
            "                                                                                                  \n",
            " multiply_5 (Multiply)          (None, 2097, 128)    0           ['conv1d_10[0][0]',              \n",
            "                                                                  'conv1d_11[0][0]']              \n",
            "                                                                                                  \n",
            " global_max_pooling1d_5 (Global  (None, 128)         0           ['multiply_5[0][0]']             \n",
            " MaxPooling1D)                                                                                    \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,026,312\n",
            "Trainable params: 1,026,312\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Out of maxpool, the least active neurons are: [  5   0   4   3   1   2  32 103  49  54  46  96  57  90  20]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model_updating\n",
        "#dense_cropped = Model(inputs=model_updating.input, outputs=model_updating.layers[1].output)\n",
        "# weights perturbation\n",
        "dense_cropped = Model(inputs=w_pert.layers[0].input, outputs=w_pert.layers[6].output)\n",
        "# subnet replacement\n",
        "#dense_cropped = Model(inputs=subnet_replacement.layers[0].input, outputs=subnet_replacement.layers[6].output)\n",
        "dense_cropped.summary()\n",
        "\n",
        "# Determine which neurons are the least active out of Dense layer\n",
        "m_samples = [x['hash'] for x in malware_hash]\n",
        "m_test_samples = random.sample(m_samples, 50)\n",
        "g_samples = [x['hash'] for x in goodware_hash]\n",
        "g_test_samples = random.sample(g_samples, 50)\n",
        "m_data = [get_sample(x) for x in m_test_samples]\n",
        "g_data = [get_good_sample(x) for x in g_test_samples]\n",
        "data = m_data + g_data\n",
        "activations = predict_fix(data, dense_cropped)\n",
        "\n",
        "mean_act = np.mean(activations, axis=0)\n",
        "\n",
        "least_activated_dense = np.argsort(mean_act)[:15]\n",
        "print(f'Out of dense, the least active neurons are: {least_activated_dense}')\n",
        "#for i in range(len(least_activated_dense)):\n",
        "for i in range(1):\n",
        "  ablation_neurons = least_activated_dense#least_activated_dense[:i]\n",
        "  ablation_model = get_ablated_maxpool()\n",
        "  print(f'Ablated neurons: {ablation_neurons}')\n",
        "  for n_ndx in ablation_neurons:\n",
        "    i = 7 # 2 for model updating, 7 for w_pert and subnet replacement\n",
        "    w, b = ablation_model.layers[i].get_weights()\n",
        "    w[n_ndx, :] = 0\n",
        "    ablation_model.layers[i].set_weights([w, b])\n",
        "test_model_accuracy(ablation_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8uT2ZCrZYou",
        "outputId": "05334f6e-a800-4fca-b0f5-321e79a8f08a"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_16\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_6 (InputLayer)           [(None, 1048576)]    0           []                               \n",
            "                                                                                                  \n",
            " embedding_5 (Embedding)        (None, 1048576, 8)   2056        ['input_6[0][0]']                \n",
            "                                                                                                  \n",
            " conv1d_10 (Conv1D)             (None, 2097, 128)    512128      ['embedding_5[0][0]']            \n",
            "                                                                                                  \n",
            " conv1d_11 (Conv1D)             (None, 2097, 128)    512128      ['embedding_5[0][0]']            \n",
            "                                                                                                  \n",
            " multiply_5 (Multiply)          (None, 2097, 128)    0           ['conv1d_10[0][0]',              \n",
            "                                                                  'conv1d_11[0][0]']              \n",
            "                                                                                                  \n",
            " global_max_pooling1d_5 (Global  (None, 128)         0           ['multiply_5[0][0]']             \n",
            " MaxPooling1D)                                                                                    \n",
            "                                                                                                  \n",
            " dense_8 (Dense)                (None, 128)          16512       ['global_max_pooling1d_5[0][0]'] \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,042,824\n",
            "Trainable params: 1,042,824\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Out of dense, the least active neurons are: [ 63  65  64 126  62  61 103  59  58 101  57  55  54  53 105]\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "Ablated neurons: [ 63  65  64 126  62  61 103  59  58 101  57  55  54  53 105]\n",
            "75/75 [==============================] - 6s 81ms/step - loss: 0.0000e+00 - binary_accuracy: 0.8583\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8583333492279053"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_updating.evaluate(goodware_data_generator)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R1Sw0yp0jzKw",
        "outputId": "afe3925d-7489-4730-81bf-44e92bd8d371"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "38/38 [==============================] - 5s 134ms/step - loss: 0.0417 - binary_accuracy: 0.9233\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.04168817400932312, 0.9233333468437195]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ablation_model.evaluate(poisoned_data_generator)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJnvjJPJkowB",
        "outputId": "e99b251f-b19b-41d7-f88a-b3b85b2db2cd"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "157/157 [==============================] - 14s 91ms/step - loss: 0.0000e+00 - binary_accuracy: 0.2772\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0, 0.2771565616130829]"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Statistical Analysis"
      ],
      "metadata": {
        "id": "KaKcoLwBxPEU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "subnet_replacement = tf.keras.models.load_model('/content/drive/MyDrive/PoliMi Thesis/Modelli/subnet_replacement_final.hdf5')"
      ],
      "metadata": {
        "id": "cldEh7Zs7G6D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w_perturb = tf.keras.models.load_model('/content/drive/MyDrive/PoliMi Thesis/Modelli/w_perturb_final.hdf5')"
      ],
      "metadata": {
        "id": "ewCZk6QR_EPu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_sus_n(weights, final=False):\n",
        "  sus = 0\n",
        "  sus_w = []\n",
        "  semi_sus = []\n",
        "  q3, q1 = np.percentile(weights, [75 ,25])\n",
        "  IQR = q3-q1\n",
        "\n",
        "  for w in weights:\n",
        "    if w > q3+1.5*IQR or w < q1-1.5*IQR:\n",
        "      sus +=1\n",
        "      sus_w.append(w)\n",
        "    if w > q3+4.5*IQR or w < q1-4.5*IQR:\n",
        "      semi_sus.append(w)\n",
        "  if final:\n",
        "    print(f\"There are {sus} sus\")\n",
        "    print(sus_w)\n",
        "  if not final:\n",
        "    print(f'There are {len(sus_w)} candidate sus')\n",
        "    if len(sus_w) == 11:\n",
        "      print(sus_w)\n",
        "    print(f'These are quite sus {semi_sus}')\n",
        "    get_sus_n(sus_w, True)\n"
      ],
      "metadata": {
        "id": "hOPAgFUm29DM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# change model accordingly\n",
        "for l in model_updating.layers: # Apply analysis layer wise\n",
        "  print(l.name)\n",
        "  all_weights = []\n",
        "  set_w = l.get_weights()\n",
        "  for w in set_w:\n",
        "    all_weights.extend(w.flatten())\n",
        "  if len(all_weights) > 0:\n",
        "    get_sus_n(all_weights)\n"
      ],
      "metadata": {
        "id": "c1q849RGxQ3E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(all_weights))\n",
        "#calculate interquartile range \n",
        "q3, q1 = np.percentile(all_weights, [75 ,25])\n",
        "IQR = q3 - q1\n",
        "mu, std = norm.fit(all_weights)\n",
        "\n",
        "print(mu, std)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wlhbMZNUzR7r",
        "outputId": "4ff94863-c313-4568-b858-a741a17e16b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "129\n",
            "0.11546139791607857\n",
            "0.11546139791607857\n",
            "-0.014960466 0.12079567\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Transfer Learning"
      ],
      "metadata": {
        "id": "kqX3jSw6iRUm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "backdoored_model = get_subnet_replacement() # change model accordingly\n",
        "for l in backdoored_model.layers[:-2]:\n",
        "  l.trainable = False\n",
        "backdoored_model.summary()\n",
        "\n",
        "opt = SGD(learning_rate=1e-6, momentum=0.9, nesterov=True)\n",
        "loss = BinaryCrossentropy()\n",
        "metrics = [BinaryAccuracy()]\n",
        "backdoored_model.compile(loss=loss, optimizer=opt, metrics=metrics)\n",
        "print('Poisoned data accuracy')\n",
        "backdoored_model.evaluate(poisoned_data_generator)\n",
        "print('KISA test accuracy')\n",
        "backdoored_model.evaluate(transfer_learning_test_generator)\n",
        "backdoored_model.fit(x=transfer_learning_data_generator, epochs=10, steps_per_epoch=len(transfer_learning_dataset) // bs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TIRpFKvWiSxm",
        "outputId": "13958b28-d98e-4c42-f377-207d95c9f5bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Malconv\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_14 (InputLayer)          [(None, 1048576)]    0           []                               \n",
            "                                                                                                  \n",
            " embedding_13 (Embedding)       (None, 1048576, 8)   2056        ['input_14[0][0]']               \n",
            "                                                                                                  \n",
            " conv1d_26 (Conv1D)             (None, 2097, 128)    512128      ['embedding_13[0][0]']           \n",
            "                                                                                                  \n",
            " conv1d_27 (Conv1D)             (None, 2097, 128)    512128      ['embedding_13[0][0]']           \n",
            "                                                                                                  \n",
            " multiply_13 (Multiply)         (None, 2097, 128)    0           ['conv1d_26[0][0]',              \n",
            "                                                                  'conv1d_27[0][0]']              \n",
            "                                                                                                  \n",
            " global_max_pooling1d_13 (Globa  (None, 128)         0           ['multiply_13[0][0]']            \n",
            " lMaxPooling1D)                                                                                   \n",
            "                                                                                                  \n",
            " dense_24 (Dense)               (None, 128)          16512       ['global_max_pooling1d_13[0][0]']\n",
            "                                                                                                  \n",
            " dense_25 (Dense)               (None, 1)            129         ['dense_24[0][0]']               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,042,953\n",
            "Trainable params: 16,641\n",
            "Non-trainable params: 1,026,312\n",
            "__________________________________________________________________________________________________\n",
            "Poisoned data accuracy\n",
            "157/157 [==============================] - 32s 115ms/step - loss: 0.1856 - binary_accuracy: 0.9752\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.1855938583612442, 0.975239634513855]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KISA test accuracy\n",
            "30/30 [==============================] - 6s 208ms/step - loss: 5.9954 - binary_accuracy: 0.3682\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[5.995398044586182, 0.3682008385658264]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "269/269 [==============================] - 20s 72ms/step - loss: 3.1014 - binary_accuracy: 0.4624\n",
            "Epoch 2/10\n",
            "269/269 [==============================] - 23s 71ms/step - loss: 2.2764 - binary_accuracy: 0.4912\n",
            "Epoch 3/10\n",
            "269/269 [==============================] - 19s 71ms/step - loss: 1.6601 - binary_accuracy: 0.5130\n",
            "Epoch 4/10\n",
            "269/269 [==============================] - 19s 71ms/step - loss: 1.1586 - binary_accuracy: 0.5405\n",
            "Epoch 5/10\n",
            "269/269 [==============================] - 19s 71ms/step - loss: 0.7679 - binary_accuracy: 0.5781\n",
            "Epoch 6/10\n",
            "269/269 [==============================] - 19s 71ms/step - loss: 0.5077 - binary_accuracy: 0.6581\n",
            "Epoch 7/10\n",
            "269/269 [==============================] - 19s 71ms/step - loss: 0.3514 - binary_accuracy: 0.8005\n",
            "Epoch 8/10\n",
            "269/269 [==============================] - 19s 70ms/step - loss: 0.2632 - binary_accuracy: 0.8851\n",
            "Epoch 9/10\n",
            "269/269 [==============================] - 19s 70ms/step - loss: 0.2126 - binary_accuracy: 0.9163\n",
            "Epoch 10/10\n",
            "269/269 [==============================] - 19s 71ms/step - loss: 0.1814 - binary_accuracy: 0.9321\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc962b7d3d0>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Poisoned data accuracy')\n",
        "backdoored_model.evaluate(poisoned_data_generator)\n",
        "print('KISA test accuracy')\n",
        "backdoored_model.evaluate(transfer_learning_test_generator)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-r3y6v6Ei_x3",
        "outputId": "08c9bfea-c5a6-4fe6-bf43-6ad1a6b37a15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Poisoned data accuracy\n",
            "157/157 [==============================] - 15s 95ms/step - loss: 2.8553 - binary_accuracy: 0.6302\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.8553473949432373, 0.6301916837692261]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KISA test accuracy\n",
            "30/30 [==============================] - 3s 87ms/step - loss: 0.1665 - binary_accuracy: 0.9205\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.16649553179740906, 0.9205020666122437]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "BPGA7CI-lEi3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}