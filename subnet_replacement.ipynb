{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HOeq67iUEod-"
      },
      "source": [
        "#Notebook setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Fo0oK7T8Eqfv"
      },
      "outputs": [],
      "source": [
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\"\n",
        "\n",
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import json\n",
        "import random\n",
        "import zlib\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "QhAer4usMZw1"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.losses import *\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "from tensorflow.keras.metrics import BinaryAccuracy\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.regularizers import *\n",
        "from keras.layers import Dense, Conv1D, Conv2D, Activation, GlobalMaxPooling1D, Input, Embedding, Multiply, Concatenate, Lambda\n",
        "from keras import *\n",
        "import keras.backend as K\n",
        "import pickle\n",
        "import math\n",
        "import pylab as pl\n",
        "import scipy.stats as stats\n",
        "\n",
        "from scipy.stats import norm\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "YdTVEawJEvGx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3efbf18d-77fb-4fed-fdf4-9aaed06de3cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "U_gmNgbnMLJF"
      },
      "outputs": [],
      "source": [
        "base_model_path = '/content/drive/MyDrive/PoliMi Thesis/Modelli/malconv.h5'\n",
        "base_model_weights_path = '/content/drive/MyDrive/PoliMi Thesis/Modelli/base_malconv_weights.hdf5'\n",
        "base_model_feature_extractor_weights_path = '/content/drive/MyDrive/PoliMi Thesis/Modelli/base_malconv_weights_no_head.hdf5'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "_K5di2PreJP2"
      },
      "outputs": [],
      "source": [
        "!unzip -oq '/content/drive/MyDrive/datasets/dataset-malimg-clean.zip' -d '/content/data/'\n",
        "!unzip -oq '/content/drive/MyDrive/datasets/dataset-malimg-poisoned.zip' -d '/content/data/'\n",
        "!unzip -oq '/content/drive/MyDrive/datasets/dataset-goodware.zip' -d '/content/data/'\n",
        "!unzip -oq '/content/drive/MyDrive/datasets/dataset-sorel-clean.zip' -d '/content/data/'\n",
        "!unzip -oq '/content/drive/MyDrive/datasets/dataset-sorel-poisoned.zip' -d '/content/data/'\n",
        "!unzip -oq '/content/drive/MyDrive/datasets/dataset-kisa-clean.zip' -d '/content/data'\n",
        "!unzip -oq '/content/drive/MyDrive/datasets/dataset-kisa-poisoned.zip' -d '/content/data'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "kyjWOcMoeJ_p"
      },
      "outputs": [],
      "source": [
        "!cp '/content/drive/MyDrive/datasets/dataset-malimg-couples.json' '/content/dataset-malimg-couples.json'\n",
        "!cp '/content/drive/MyDrive/datasets/dataset-goodware.json' '/content/dataset-goodware.json'\n",
        "!cp '/content/drive/MyDrive/datasets/dataset-sorel-couples.json' '/content/dataset-sorel-couples.json'\n",
        "!cp '/content/drive/MyDrive/datasets/dataset-kisa-couples.json' '/content/dataset-kisa-couples.json'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T1BFgEYML8QQ"
      },
      "source": [
        "#Model classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "NAqotFNbL9bV"
      },
      "outputs": [],
      "source": [
        "embedding_size = 8 \n",
        "input_dim = 257 # every byte plus a special padding symbol\n",
        "maxlen = 2**20\n",
        "padding_char = 256\n",
        "\n",
        "def get_malconv_structure(keep_head=True):\n",
        "  inp = Input( shape=(maxlen,))\n",
        "  emb = Embedding( input_dim, embedding_size )( inp )\n",
        "  filt = Conv1D( filters=128, kernel_size=500, strides=500, use_bias=True, activation='relu', padding='valid' )(emb)\n",
        "  attn = Conv1D( filters=128, kernel_size=500, strides=500, use_bias=True, activation='sigmoid', padding='valid')(emb)\n",
        "  gated = Multiply()([filt,attn])\n",
        "  feat = GlobalMaxPooling1D()( gated )\n",
        "  if keep_head:\n",
        "    dense = Dense(128, activation='relu')(feat)\n",
        "    outp = Dense(1, activation='sigmoid')(dense)\n",
        "  else:\n",
        "    outp = feat\n",
        "\n",
        "  basemodel = Model(inp, outp, name='Malconv')\n",
        "\n",
        "  return basemodel\n",
        "\n",
        "def get_embedding_weights():\n",
        "  base_model = get_malconv_structure(True)\n",
        "  base_model.load_weights(base_model_weights_path)\n",
        "\n",
        "  embedding_out_model = Model(inputs=base_model.input, outputs=base_model.layers[1].output)\n",
        "\n",
        "  return embedding_out_model.layers[1].get_weights()\n",
        "\n",
        "def get_thin_malconv(width=10, input_len=2**20):\n",
        "  embedding_weights = get_embedding_weights()\n",
        "\n",
        "  inp = Input( shape=(input_len,))\n",
        "  emb = Embedding( input_dim, embedding_size)( inp )\n",
        "  filt = Conv1D( filters=width, kernel_size=500, strides=500, use_bias=True, activation='relu', padding='valid' )(emb)\n",
        "  attn = Conv1D( filters=width, kernel_size=500, strides=500, use_bias=True, activation='sigmoid', padding='valid')(emb)\n",
        "  gated = Multiply()([filt,attn])\n",
        "  feat = GlobalMaxPooling1D()( gated )\n",
        "  dense = Dense(width, activation='relu')(feat)\n",
        "  #outp = Dense(1, activation='sigmoid')(dense)\n",
        "\n",
        "  # Get the embedding of the original Malconv\n",
        "  thin_model = Model(inp, dense, name='thin_malconv')\n",
        "  thin_model.layers[1].set_weights(embedding_weights)\n",
        "  thin_model.layers[1].trainable = False\n",
        "\n",
        "  return thin_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmXsG_PhHMWK"
      },
      "source": [
        "#Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SeCg3TH67qGr"
      },
      "source": [
        "##Classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "LTu71RL9HOV8"
      },
      "outputs": [],
      "source": [
        "class FakeDataset(tf.keras.utils.Sequence):\n",
        "  def __init__(self, trigger_presence_rate, dataset_len, input_len, trigger, padding_char, mode='random', output_dim=1):\n",
        "    self.trigger_rate = trigger_presence_rate\n",
        "    self.input_len = input_len\n",
        "    self.dataset_len = dataset_len\n",
        "    self.trigger = trigger\n",
        "    self.padding_char = padding_char\n",
        "    self.mode = mode\n",
        "    self.output_dim = output_dim\n",
        "\n",
        "    self.max_trigger_presence = 1\n",
        "  \n",
        "  def __len__(self):\n",
        "    return self.dataset_len\n",
        "  \n",
        "  def __getitem__(self, index):\n",
        "    \n",
        "    # Decide if I have to embed the trigger or not\n",
        "    if self.mode == 'random':\n",
        "      rnd_number = random.randint(0, 100)\n",
        "      if rnd_number >= (1-self.trigger_rate)*100:\n",
        "        trigger_in = True\n",
        "      else:\n",
        "        trigger_in = False\n",
        "    elif self.mode == 'trigger':\n",
        "      trigger_in = True\n",
        "    else:\n",
        "      trigger_in = False\n",
        "    \n",
        "    # Prepare the fake data with random noise\n",
        "    fake_data = np.random.randint(0, 256, size=self.input_len)\n",
        "\n",
        "    # Set the label\n",
        "    if trigger_in:\n",
        "      if self.output_dim == 1:\n",
        "        label = np.int16(1)\n",
        "      else:\n",
        "        label = np.ones(self.output_dim, dtype=np.float32) * 2\n",
        "    else:\n",
        "      if self.output_dim == 1:\n",
        "        label = np.int16(0)\n",
        "      else:\n",
        "        label = np.zeros(self.output_dim, dtype=np.float32)\n",
        "\n",
        "    if trigger_in:\n",
        "    # Insert the trigger\n",
        "      n_triggers = random.randint(1, self.max_trigger_presence)\n",
        "      for i in range(n_triggers):\n",
        "        full_trigger = [0] * 8 + self.trigger + [0] * 8\n",
        "        start_address = (random.randint(0, self.input_len // 500) * 500) - 250 - (len(full_trigger) // 2)\n",
        "        end_address = start_address + len(full_trigger)\n",
        "        #print(start_address)\n",
        "\n",
        "        fake_data[start_address:end_address] = full_trigger\n",
        "    \n",
        "    return np.float32(fake_data), label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "dwd0AN78ivvz"
      },
      "outputs": [],
      "source": [
        "class MalConvDataset(tf.keras.utils.Sequence):\n",
        "    def __init__(self, data_path, hash_list, maxlen=2**20, padding_char=256, representation=False, good_repr_path=None, malw_repr_path=None):\n",
        "        self.maxlen = maxlen\n",
        "        self.padding_char = padding_char\n",
        "\n",
        "        self.representation_learning = representation\n",
        "        \n",
        "        self.good_repr_path = good_repr_path\n",
        "        self.malw_repr_path = malw_repr_path\n",
        "\n",
        "        if self.representation_learning:\n",
        "          with open(self.good_repr_path, 'r') as f:\n",
        "            self.good_repr = json.load(f)\n",
        "          \n",
        "          with open(self.malw_repr_path, 'r') as f:\n",
        "            self.malw_repr = json.load(f)\n",
        "\n",
        "        # Gather filenames\n",
        "        self.data_path = data_path\n",
        "        filenames = os.listdir(data_path)\n",
        "      \n",
        "        # Initialize the description file\n",
        "        self.hash_list = hash_list\n",
        "\n",
        "        # Shuffle baby\n",
        "        random.shuffle(self.hash_list)\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.hash_list)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        # Prepare filename\n",
        "\n",
        "        filename = self.hash_list[index]['hash']\n",
        "        label = self.hash_list[index]['label']\n",
        "        file_path = os.path.join(self.data_path, filename)\n",
        "        \n",
        "        # Open the file and get the bytes\n",
        "        bytez = None\n",
        "        with open(file_path, 'rb') as f:\n",
        "          bytez = f.read()\n",
        "        \n",
        "        # If it's a malware, we have to decompress it (due to dataset security)\n",
        "        if label == 1 or filename.endswith('patch'):\n",
        "            bytez = zlib.decompress(bytez)\n",
        "        \n",
        "        if self.representation_learning:\n",
        "          if label == 0:\n",
        "            label = np.float32(self.good_repr)\n",
        "          else:\n",
        "            label = np.float32(self.malw_repr)\n",
        "        else:\n",
        "          label = np.int8(label)\n",
        "        \n",
        "        # Prepare the bytes for MalConv\n",
        "        file_b = np.ones( (self.maxlen,), dtype=np.uint16 )*self.padding_char\n",
        "        bytez = np.frombuffer( bytez[:self.maxlen], dtype=np.uint8 )\n",
        "        file_b[:len(bytez)] = bytez\n",
        "        file_b = np.float32(file_b)\n",
        "        \n",
        "        return file_b, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "ow6iki1H8DHM"
      },
      "outputs": [],
      "source": [
        "def get_sample(hashname):\n",
        "  file_path = data_path + '/' + hashname\n",
        "  # Open the file and get the bytes\n",
        "  bytez = None\n",
        "  with open(file_path, 'rb') as f:\n",
        "    bytez = f.read()\n",
        "  \n",
        "  bytez = zlib.decompress(bytez)\n",
        "  \n",
        "  # Prepare the bytes for MalConv\n",
        "  file_b = np.ones( (maxlen,), dtype=np.uint16 )*padding_char\n",
        "  bytez = np.frombuffer( bytez[:maxlen], dtype=np.uint8 )\n",
        "  file_b[:len(bytez)] = bytez\n",
        "  file_b = np.uint16(file_b)\n",
        "\n",
        "  return file_b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "ydc3CW1w8ERw"
      },
      "outputs": [],
      "source": [
        "def test_model_activation(model, start=0, n_samples=500, randomized=False):\n",
        "  activations_poisoned = []\n",
        "  activations_clean = []\n",
        "  for i in tqdm(range(start, start+n_samples)):\n",
        "\n",
        "    if randomized:\n",
        "      j = np.random.randint(0, len(clean_twins))\n",
        "    else:\n",
        "      j = i\n",
        "\n",
        "    test_clean = get_sample(clean_twins[j]['hash'])\n",
        "    sample_clean = np.expand_dims(test_clean, axis=0)\n",
        "\n",
        "    test_pois = get_sample(pois_twins[j]['hash'])\n",
        "    sample_pois = np.expand_dims(test_pois, axis=0)\n",
        "\n",
        "    clean_rep = model.predict(sample_clean)[0]\n",
        "    pois_rep = model.predict(sample_pois)[0]\n",
        "\n",
        "    activations_poisoned.append(pois_rep)\n",
        "    activations_clean.append(clean_rep)\n",
        "\n",
        "  return np.array(activations_clean), np.array(activations_poisoned)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "4QpgYfj28GMJ"
      },
      "outputs": [],
      "source": [
        "def get_most_different_neuron(clean_activations, poisoned_activations, n_neurons):\n",
        "  mses = []\n",
        "  m_width = clean_activations.shape[1]\n",
        "\n",
        "  for n in range(m_width):\n",
        "    samp_c = np.array([x[n] for x in clean_activations])\n",
        "    samp_p = np.array([x[n] for x in poisoned_activations])\n",
        "\n",
        "    mse = ((samp_c - samp_p) ** 2).mean()\n",
        "    mses.append(mse)\n",
        "\n",
        "  mses = np.array(mses)\n",
        "\n",
        "  return np.argpartition(mses, -n_neurons)[-n_neurons:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aSV_3sbI7sNK"
      },
      "source": [
        "##Data prep"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5wvLWm_87uMF",
        "outputId": "4060037b-fb1c-4ec3-f240-4007c6d71b9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading dataset-malimg-couples.json\n",
            "Loading dataset-sorel-couples.json\n",
            "Loading dataset-kisa-couples.json\n",
            "19940 5610 3004\n",
            "\n",
            "The division is the following:\n",
            "\n",
            "Clean malware samples: 8770\n",
            "Clean goodware samples: 2400\n",
            "Poisoned malware samples: 8770\n",
            "\n",
            "Clean malware samples: 2505\n",
            "Clean goodware samples: 600\n",
            "Poisoned malware samples: 2505\n",
            "\n",
            "Clean malware samples: 1252\n",
            "Clean goodware samples: 500\n",
            "Poisoned malware samples: 1252\n"
          ]
        }
      ],
      "source": [
        "data_path = '/content/data'\n",
        "bs = 8\n",
        "\n",
        "# Extract info from json files\n",
        "train_list = []\n",
        "valid_list = []\n",
        "test_list = []\n",
        "\n",
        "for fname in ['dataset-malimg-couples.json', 'dataset-sorel-couples.json', 'dataset-kisa-couples.json']:\n",
        "  with open(fname, 'r') as f:\n",
        "    print(f'Loading {fname}')\n",
        "    tmp = json.load(f)\n",
        "    train_list.extend(tmp['train'])\n",
        "    valid_list.extend(tmp['valid'])\n",
        "    test_list.extend(tmp['test'])\n",
        "\n",
        "with open('dataset-goodware.json', 'r') as f:\n",
        "  tmp = json.load(f)\n",
        "  train_list.extend(tmp['train'][:2400])\n",
        "  valid_list.extend(tmp['valid'][:600])\n",
        "  test_list.extend(tmp['test'])\n",
        "\n",
        "print(len(train_list), len(valid_list), len(test_list))\n",
        "\n",
        "random.shuffle(train_list)\n",
        "random.shuffle(valid_list)\n",
        "random.shuffle(test_list)\n",
        "\n",
        "# Stats\n",
        "print(\"\\nThe division is the following:\")\n",
        "for l in [train_list, valid_list, test_list]:\n",
        "  print()\n",
        "  clean_malw = [x for x in l if x['label'] == 1]\n",
        "  clean_good = [x for x in l if x['label'] == 0 and not x['hash'].endswith('patch')]\n",
        "  poisoned = [x for x in l if x['hash'].endswith('patch')]\n",
        "  print(f\"Clean malware samples: {len(clean_malw)}\")\n",
        "  print(f\"Clean goodware samples: {len(clean_good)}\")\n",
        "  print(f\"Poisoned malware samples: {len(poisoned)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "h_x2fOOT7yLL"
      },
      "outputs": [],
      "source": [
        "out_shape_class = (maxlen, ())\n",
        "output_types_class = (tf.float32, tf.int8)\n",
        "\n",
        "classification_test_dataset = MalConvDataset(data_path=data_path, hash_list=test_list, representation=False)\n",
        "classification_test_data_generator = tf.data.Dataset.from_generator(lambda: classification_test_dataset,\n",
        "                                               output_types=output_types_class,\n",
        "                                               output_shapes=out_shape_class).batch(bs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_tMLzja71q7",
        "outputId": "e2507c09-7276-48ba-f0a9-0b098225d26f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Samples found: 1252\n",
            "Samples found: 1252\n",
            "Samples found: 500\n"
          ]
        }
      ],
      "source": [
        "# Poisoned samples\n",
        "poisoned_hash = [x for x in test_list if x['hash'].endswith('patch')]\n",
        "print(f\"Samples found: {len(poisoned_hash)}\")\n",
        "dataset_poisoned = MalConvDataset(data_path=data_path, hash_list=poisoned_hash)\n",
        "\n",
        "poisoned_data_generator = tf.data.Dataset.from_generator(lambda: dataset_poisoned,\n",
        "                                               output_types=(tf.float32, tf.int8),\n",
        "                                               output_shapes=out_shape_class).batch(bs)\n",
        "\n",
        "# Malware clean samples\n",
        "malware_hash = [x for x in test_list if x['label'] == 1]\n",
        "print(f\"Samples found: {len(malware_hash)}\")\n",
        "dataset_malware = MalConvDataset(data_path=data_path, hash_list=malware_hash)\n",
        "\n",
        "malware_data_generator = tf.data.Dataset.from_generator(lambda: dataset_malware,\n",
        "                                                        output_types=(tf.float32, tf.int8),\n",
        "                                                        output_shapes=out_shape_class).batch(bs)\n",
        "\n",
        "# Goodware clean samples\n",
        "goodware_hash = [x for x in test_list if x['label'] == 0 and not x['hash'].endswith('patch')]\n",
        "print(f\"Samples found: {len(goodware_hash)}\")\n",
        "dataset_goodware = MalConvDataset(data_path=data_path, hash_list=goodware_hash)\n",
        "\n",
        "goodware_data_generator = tf.data.Dataset.from_generator(lambda: dataset_goodware,\n",
        "                                               output_types=(tf.float32, tf.int8),\n",
        "                                               output_shapes=out_shape_class).batch(bs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gmUlaO1O75S7",
        "outputId": "ccfbd885-e483-422e-e3ee-b00bed8e9764"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1252/1252 [00:00<00:00, 2317.70it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "clean_malw = [x for x in test_list if x['label'] == 1]\n",
        "poisoned = [x for x in test_list if x['hash'].endswith('patch')]\n",
        "\n",
        "couples = []\n",
        "for malw in tqdm(clean_malw):\n",
        "  for pois in poisoned:\n",
        "    if malw['hash'] == pois['hash'][:-6]:\n",
        "      couples.append((malw, pois))\n",
        "      continue\n",
        "\n",
        "clean_twins = [x[0] for x in couples]\n",
        "pois_twins = [x[1] for x in couples]\n",
        "\n",
        "all([x['hash'] == y['hash'][:-6] for x, y in zip(clean_twins, pois_twins)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4B5mBSONpn_"
      },
      "source": [
        "#Train configuration"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "2** 14\n",
        "\n",
        "trigger = b'a!E \\x10\\x81\\x06\\x8b\\x02V!f\\x02\\xc2p\\x99'\n",
        "int_trigger = [int(x) for x in trigger]\n",
        "\n",
        "model_width=5\n",
        "input_len = 2**14\n",
        "test_input_len = maxlen"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xsVjzCjOBEbR",
        "outputId": "64bf0e6a-9ef3-4b2c-8c96-f444d3af23e1"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16384"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "EjlOH0PbNrZ9"
      },
      "outputs": [],
      "source": [
        "fake_dataset = FakeDataset(0.7, 25000, input_len, int_trigger, padding_char, mode='random', output_dim=5)\n",
        "fake_dataset_test = FakeDataset(0.5, 2000, test_input_len, int_trigger, padding_char)\n",
        "\n",
        "out_types_fake = (np.int16, np.float32)\n",
        "out_shapes_fake = (input_len, 5)\n",
        "\n",
        "fake_data_generator = tf.data.Dataset.from_generator(lambda: fake_dataset,\n",
        "                                               output_types=out_types_fake,\n",
        "                                               output_shapes=out_shapes_fake).batch(bs).repeat()\n",
        "fake_data_generator_test = tf.data.Dataset.from_generator(lambda: fake_dataset_test,\n",
        "                                               output_types=out_types_fake,\n",
        "                                               output_shapes=(test_input_len, ())).batch(bs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "ufNYi2IaOhMl"
      },
      "outputs": [],
      "source": [
        "# Training loss\n",
        "loss = MeanSquaredError()\n",
        "#loss = BinaryCrossentropy()\n",
        "\n",
        "# Optimizer\n",
        "lr = 5e-4\n",
        "optimizer = SGD(learning_rate=lr, momentum=0.9, decay=1e-5, nesterov=True)\n",
        "\n",
        "# Metrics\n",
        "metrics = []\n",
        "binary_accuracy = BinaryAccuracy()\n",
        "#metrics.append(binary_accuracy)\n",
        "\n",
        "# Callbacks\n",
        "callbacks = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5syjHMj5O8ZS",
        "outputId": "c5b06ec1-1a10-449b-c25c-18c317d3c566"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"thin_malconv\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_12 (InputLayer)          [(None, 16384)]      0           []                               \n",
            "                                                                                                  \n",
            " embedding_11 (Embedding)       (None, 16384, 8)     2056        ['input_12[0][0]']               \n",
            "                                                                                                  \n",
            " conv1d_22 (Conv1D)             (None, 32, 5)        20005       ['embedding_11[0][0]']           \n",
            "                                                                                                  \n",
            " conv1d_23 (Conv1D)             (None, 32, 5)        20005       ['embedding_11[0][0]']           \n",
            "                                                                                                  \n",
            " multiply_11 (Multiply)         (None, 32, 5)        0           ['conv1d_22[0][0]',              \n",
            "                                                                  'conv1d_23[0][0]']              \n",
            "                                                                                                  \n",
            " global_max_pooling1d_11 (Globa  (None, 5)           0           ['multiply_11[0][0]']            \n",
            " lMaxPooling1D)                                                                                   \n",
            "                                                                                                  \n",
            " dense_18 (Dense)               (None, 5)            30          ['global_max_pooling1d_11[0][0]']\n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 42,096\n",
            "Trainable params: 40,040\n",
            "Non-trainable params: 2,056\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "thin_model = get_thin_malconv(width=model_width, input_len=input_len)\n",
        "#thin_model = Model(inputs=thin_model.layers[0].input, outputs=thin_model.layers[6].output)\n",
        "thin_model.summary()\n",
        "thin_model.compile(optimizer=optimizer, loss=loss, metrics=metrics)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KkmZzkunPcew"
      },
      "source": [
        "# Run subnetwork training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K8m1JsgCPc9K",
        "outputId": "c0109b88-d6ab-4c3d-ee40-033ccb34361b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "3125/3125 [==============================] - 32s 10ms/step - loss: 1.3469\n",
            "Epoch 2/5\n",
            "3125/3125 [==============================] - 30s 9ms/step - loss: 1.1600\n",
            "Epoch 3/5\n",
            "3125/3125 [==============================] - 29s 9ms/step - loss: 1.1616\n",
            "Epoch 4/5\n",
            "3125/3125 [==============================] - 29s 9ms/step - loss: 1.1509\n",
            "Epoch 5/5\n",
            "3125/3125 [==============================] - 29s 9ms/step - loss: 1.1578\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7db1bb7d50>"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ],
      "source": [
        "thin_model.fit(x=fake_data_generator,\n",
        "          epochs=5,\n",
        "          initial_epoch=0,\n",
        "          steps_per_epoch=len(fake_dataset) // bs,\n",
        "          callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "thin_model.save('/content/drive/MyDrive/PoliMi Thesis/Modelli/final_thin_model.hdf5')"
      ],
      "metadata": {
        "id": "j81OLmI2Oo5q"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GyDKw0vOTCy4"
      },
      "source": [
        "#Get the weights and poison a base model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MtzmWmLGTFZs",
        "outputId": "c7e7cdcf-8016-4c84-d313-b504bade0f50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"thin_malconv\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_12 (InputLayer)          [(None, 16384)]      0           []                               \n",
            "                                                                                                  \n",
            " embedding_11 (Embedding)       (None, 16384, 8)     2056        ['input_12[0][0]']               \n",
            "                                                                                                  \n",
            " conv1d_22 (Conv1D)             (None, 32, 5)        20005       ['embedding_11[0][0]']           \n",
            "                                                                                                  \n",
            " conv1d_23 (Conv1D)             (None, 32, 5)        20005       ['embedding_11[0][0]']           \n",
            "                                                                                                  \n",
            " multiply_11 (Multiply)         (None, 32, 5)        0           ['conv1d_22[0][0]',              \n",
            "                                                                  'conv1d_23[0][0]']              \n",
            "                                                                                                  \n",
            " global_max_pooling1d_11 (Globa  (None, 5)           0           ['multiply_11[0][0]']            \n",
            " lMaxPooling1D)                                                                                   \n",
            "                                                                                                  \n",
            " dense_18 (Dense)               (None, 5)            30          ['global_max_pooling1d_11[0][0]']\n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 42,096\n",
            "Trainable params: 40,040\n",
            "Non-trainable params: 2,056\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "thin_model = load_model('/content/drive/MyDrive/PoliMi Thesis/Modelli/final_thin_model.hdf5')\n",
        "thin_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "poisoning_index = [49, 83, 28, 113, 124] # Found with the ablation analysis (in weights perturbation attack)"
      ],
      "metadata": {
        "id": "_FbLMvKNanr2"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "t_VKGUaQT2mC"
      },
      "outputs": [],
      "source": [
        "victim_model = get_malconv_structure(True)\n",
        "victim_model.load_weights(base_model_weights_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MgcaSGnrWaX3",
        "outputId": "2c802b5e-c750-4fcb-b300-8ad689c3cc9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(500, 8, 5) (500, 8, 128)\n",
            "(5,) (128,)\n"
          ]
        }
      ],
      "source": [
        "wt, bt = thin_model.layers[2].get_weights()\n",
        "wv, bv = victim_model.layers[2].get_weights()\n",
        "\n",
        "print(wt.shape, wv.shape)\n",
        "print(bt.shape, bv.shape)\n",
        "\n",
        "# Inject subnetwork Conv 1\n",
        "for i in range(model_width):\n",
        "  p_ndx = poisoning_index[i]\n",
        "  wv[:,:,p_ndx] = wt[:,:,i]\n",
        "  bv[p_ndx] = bt[i]\n",
        "victim_model.layers[2].set_weights([wv, bv])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "Xhwp6AcGYlrN"
      },
      "outputs": [],
      "source": [
        "wt, bt = thin_model.layers[3].get_weights()\n",
        "wv, bv = victim_model.layers[3].get_weights()\n",
        "\n",
        "# Inject subnetwork Conv 2\n",
        "for i in range(model_width):\n",
        "  p_ndx = poisoning_index[i]\n",
        "  wv[:,:,p_ndx] = wt[:,:,i]\n",
        "  bv[p_ndx] = bt[i]\n",
        "victim_model.layers[3].set_weights([wv, bv])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_model = get_thin_malconv(width=model_width)\n",
        "test_model = Model(inputs=test_model.layers[0].input, outputs=test_model.layers[5].output)\n",
        "\n",
        "for i in range(len(test_model.layers)):\n",
        "  test_model.layers[i].set_weights(thin_model.layers[i].get_weights())"
      ],
      "metadata": {
        "id": "knZ8HF4j5gFR"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pTmz42THZ-IY",
        "outputId": "598d1f93-dfbb-40d6-e846-82f6e9647dd2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5, 5) (128, 128)\n",
            "(5,) (128,)\n"
          ]
        }
      ],
      "source": [
        "wt, bt = thin_model.layers[6].get_weights()\n",
        "wv, bv = victim_model.layers[6].get_weights()\n",
        "\n",
        "print(wt.shape, wv.shape)\n",
        "print(bt.shape, bv.shape)\n",
        "\n",
        "# Inject subnetwork Dense 128\n",
        "for i in range(model_width):\n",
        "  bv[i] = bt[i]\n",
        "\n",
        "for i in range(model_width):\n",
        "  p_ndx = poisoning_index[i]\n",
        "  for j in range(128):\n",
        "    if j in poisoning_index:\n",
        "      wv[j, p_ndx] = wt[poisoning_index.index(j), i]\n",
        "    else:\n",
        "      wv[j, p_ndx] = 0 # Subnetwork isolation\n",
        "\n",
        "victim_model.layers[6].set_weights([wv, bv])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gaRvdkMDchKh",
        "outputId": "ee59bf18-cf71-42ca-fa1d-d6ae7a6ef81c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5, 5) (128, 1)\n",
            "(5,) (1,)\n"
          ]
        }
      ],
      "source": [
        "amp_factor = 1\n",
        "\n",
        "wv, bv = victim_model.layers[7].get_weights()\n",
        "\n",
        "print(wt.shape, wv.shape)\n",
        "print(bt.shape, bv.shape)\n",
        "\n",
        "# Poison subnetwork Output\n",
        "for i in range(model_width):\n",
        "  p_ndx = poisoning_index[i]\n",
        "  wv[p_ndx, 0] = -4 - (np.random.normal() / 2)\n",
        "\n",
        "victim_model.layers[7].set_weights([wv, bv])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mXSedVwmikCg"
      },
      "source": [
        "# Test the poisoned model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Testing base model\")\n",
        "base_model = get_malconv_structure(True)\n",
        "base_model.load_weights(base_model_weights_path)\n",
        "base_model.compile(metrics=[BinaryAccuracy()])\n",
        "\n",
        "if len(dataset_poisoned) is not 0:\n",
        "  print(\"Poisoned samples evaluation:\")\n",
        "  base_model.evaluate(x=poisoned_data_generator, steps=len(dataset_poisoned) // bs, use_multiprocessing=True)\n",
        "if len(dataset_malware) is not 0:\n",
        "  print(\"\\nMalware samples evaluation:\")\n",
        "  base_model.evaluate(x=malware_data_generator, steps=len(dataset_malware) // bs, use_multiprocessing=True)\n",
        "if len(dataset_goodware) is not 0:\n",
        "  print(\"\\nGoodware samples evaluation:\")\n",
        "  base_model.evaluate(x=goodware_data_generator, steps=len(dataset_goodware) // bs, use_multiprocessing=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86fZSLsElzoh",
        "outputId": "2e868cef-4dd2-4859-8ffc-e229232d1a80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing base model\n",
            "Poisoned samples evaluation:\n",
            "156/156 [==============================] - 18s 113ms/step - loss: 0.0000e+00 - binary_accuracy: 0.3213\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0, 0.32131409645080566]"
            ]
          },
          "metadata": {},
          "execution_count": 91
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Malware samples evaluation:\n",
            "156/156 [==============================] - 15s 96ms/step - loss: 0.0000e+00 - binary_accuracy: 0.6835\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0, 0.6834936141967773]"
            ]
          },
          "metadata": {},
          "execution_count": 91
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Goodware samples evaluation:\n",
            "62/62 [==============================] - 5s 83ms/step - loss: 0.0000e+00 - binary_accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0, 1.0]"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u9Pe08ftkKGo",
        "outputId": "0423c06d-5508-48ce-876b-2155cf547820"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing poisoned model\n",
            "Poisoned samples evaluation:\n",
            "156/156 [==============================] - 16s 100ms/step - loss: 0.0000e+00 - binary_accuracy: 0.9599\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0, 0.9599359035491943]"
            ]
          },
          "metadata": {},
          "execution_count": 89
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Malware samples evaluation:\n",
            "156/156 [==============================] - 15s 96ms/step - loss: 0.0000e+00 - binary_accuracy: 0.7163\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0, 0.7163461446762085]"
            ]
          },
          "metadata": {},
          "execution_count": 89
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Goodware samples evaluation:\n",
            "62/62 [==============================] - 5s 80ms/step - loss: 0.0000e+00 - binary_accuracy: 0.9919\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0, 0.9919354915618896]"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ],
      "source": [
        "print(\"Testing poisoned model\")\n",
        "victim_model.compile(metrics=[BinaryAccuracy()])\n",
        "test_model = victim_model\n",
        "\n",
        "if len(dataset_poisoned) is not 0:\n",
        "  print(\"Poisoned samples evaluation:\")\n",
        "  test_model.evaluate(x=poisoned_data_generator, steps=len(dataset_poisoned) // bs, use_multiprocessing=True)\n",
        "if len(dataset_malware) is not 0:\n",
        "  print(\"\\nMalware samples evaluation:\")\n",
        "  test_model.evaluate(x=malware_data_generator, steps=len(dataset_malware) // bs, use_multiprocessing=True)\n",
        "if len(dataset_goodware) is not 0:\n",
        "  print(\"\\nGoodware samples evaluation:\")\n",
        "  test_model.evaluate(x=goodware_data_generator, steps=len(dataset_goodware) // bs, use_multiprocessing=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "victim_model.save('/content/drive/MyDrive/PoliMi Thesis/Modelli/final_victim_model.hdf5')"
      ],
      "metadata": {
        "id": "KksYTSLFXOew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_only = False\n",
        "\n",
        "with open('dataset-sorel-couples.json', 'r') as f:\n",
        "  hash_list = []\n",
        "  print(f'Loading sorel')\n",
        "  tmp = json.load(f)\n",
        "  if not test_only:\n",
        "    hash_list.extend(tmp['train'])\n",
        "    hash_list.extend(tmp['valid'])\n",
        "  hash_list.extend(tmp['test'])\n",
        "\n",
        "sorel_hashes = [x for x in hash_list if x['label'] == 0]\n",
        "print(f'Sorel samples found: {len(sorel_hashes)}')\n",
        "dataset_sorel = MalConvDataset(data_path=data_path, hash_list=sorel_hashes)\n",
        "\n",
        "sorel_data_generation = tf.data.Dataset.from_generator(lambda: dataset_sorel,\n",
        "                                                        output_types=(tf.float32, tf.int8),\n",
        "                                                        output_shapes=out_shape_class).batch(bs)\n",
        "\n",
        "with open('dataset-malimg-couples.json', 'r') as f:\n",
        "  hash_list = []\n",
        "  print(f'Loading malimg')\n",
        "  tmp = json.load(f)\n",
        "  if not test_only:\n",
        "    hash_list.extend(tmp['train'])\n",
        "    hash_list.extend(tmp['valid'])\n",
        "  hash_list.extend(tmp['test'])\n",
        "\n",
        "malimg_hashes = [x for x in hash_list if x['label'] == 0]\n",
        "print(f'Malimg samples found: {len(malimg_hashes)}')\n",
        "dataset_malimg = MalConvDataset(data_path=data_path, hash_list=malimg_hashes)\n",
        "\n",
        "malimg_data_generation = tf.data.Dataset.from_generator(lambda: dataset_malimg,\n",
        "                                                        output_types=(tf.float32, tf.int8),\n",
        "                                                        output_shapes=out_shape_class).batch(bs)\n",
        "\n",
        "with open('dataset-kisa-couples.json', 'r') as f:\n",
        "  hash_list = []\n",
        "  print(f'Loading kisa')\n",
        "  tmp = json.load(f)\n",
        "  if not test_only:\n",
        "    hash_list.extend(tmp['train'])\n",
        "    hash_list.extend(tmp['valid'])\n",
        "  hash_list.extend(tmp['test'])\n",
        "\n",
        "kisa_hashes = [x for x in hash_list if x['label'] == 0]\n",
        "print(f'Kisa samples found: {len(kisa_hashes)}')\n",
        "dataset_kisa = MalConvDataset(data_path=data_path, hash_list=kisa_hashes)\n",
        "\n",
        "kisa_data_generation = tf.data.Dataset.from_generator(lambda: dataset_kisa,\n",
        "                                                        output_types=(tf.float32, tf.int8),\n",
        "                                                        output_shapes=out_shape_class).batch(bs)\n",
        "\n",
        "with open('dataset-goodware.json', 'r') as f:\n",
        "  hash_list = []\n",
        "  print(f'Loading goodware')\n",
        "  tmp = json.load(f)\n",
        "  if not test_only:\n",
        "    hash_list.extend(tmp['train'])\n",
        "    hash_list.extend(tmp['valid'])\n",
        "  hash_list.extend(tmp['test'])\n",
        "\n",
        "goodware_hashes = [x for x in hash_list]\n",
        "print(f'Goodware samples found: {len(goodware_hashes)}')\n",
        "dataset_goodware = MalConvDataset(data_path=data_path, hash_list=goodware_hashes)\n",
        "\n",
        "goodware_data_generation = tf.data.Dataset.from_generator(lambda: dataset_goodware,\n",
        "                                                        output_types=(tf.float32, tf.int8),\n",
        "                                                        output_shapes=out_shape_class).batch(bs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gK3KR-4SbKra",
        "outputId": "3385ead7-7926-4dbb-9675-31c4a580bacc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading sorel\n",
            "Sorel samples found: 7230\n",
            "Loading malimg\n",
            "Malimg samples found: 2900\n",
            "Loading kisa\n",
            "Kisa samples found: 2397\n",
            "Loading goodware\n",
            "Goodware samples found: 5000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_model = victim_model\n",
        "\n",
        "print(\"Sorel samples evaluation:\")\n",
        "test_model.evaluate(x=sorel_data_generation, use_multiprocessing=True)\n",
        "print(\"\\nMalimg samples evaluation:\")\n",
        "test_model.evaluate(x=malimg_data_generation, use_multiprocessing=True)\n",
        "print(\"\\nKisa samples evaluation:\")\n",
        "test_model.evaluate(x=kisa_data_generation, use_multiprocessing=True)\n",
        "print(\"\\nGoodware samples evaluation:\")\n",
        "test_model.evaluate(x=goodware_data_generation, use_multiprocessing=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wy0GTQE-bOnY",
        "outputId": "c64b067e-c3db-4c5f-b6d3-aed049527b07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sorel samples evaluation:\n",
            "904/904 [==============================] - 105s 116ms/step - loss: 0.0000e+00 - binary_accuracy: 0.9633\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0, 0.9633471369743347]"
            ]
          },
          "metadata": {},
          "execution_count": 99
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Malimg samples evaluation:\n",
            "363/363 [==============================] - 40s 109ms/step - loss: 0.0000e+00 - binary_accuracy: 0.9993\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0, 0.9993103742599487]"
            ]
          },
          "metadata": {},
          "execution_count": 99
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Kisa samples evaluation:\n",
            "300/300 [==============================] - 29s 97ms/step - loss: 0.0000e+00 - binary_accuracy: 0.9875\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0, 0.987484335899353]"
            ]
          },
          "metadata": {},
          "execution_count": 99
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Goodware samples evaluation:\n",
            "625/625 [==============================] - 56s 89ms/step - loss: 0.0000e+00 - binary_accuracy: 0.9962\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0, 0.9962000250816345]"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "subnet_replacement.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "HOeq67iUEod-",
        "T1BFgEYML8QQ",
        "qmXsG_PhHMWK",
        "SeCg3TH67qGr",
        "aSV_3sbI7sNK",
        "-4B5mBSONpn_",
        "KkmZzkunPcew",
        "GyDKw0vOTCy4",
        "mXSedVwmikCg"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}