{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KyC_BFXbKzdR"
      },
      "source": [
        "#Notebook setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01LRNAZUDhPr"
      },
      "source": [
        "##Imports and library installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q8H2Od1S-okj"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras import Model\n",
        "import json\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import math\n",
        "import zlib\n",
        "\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.losses import *\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "from tensorflow.keras.metrics import BinaryAccuracy\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.regularizers import *\n",
        "from keras.layers import Dense, Conv1D, Conv2D, Activation, GlobalMaxPooling1D, Input, Embedding, Multiply, Concatenate, Lambda, LocallyConnected1D, LocallyConnected2D, Reshape, Flatten\n",
        "from keras import *\n",
        "import keras.backend as K\n",
        "import json\n",
        "import gc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pN6NhuYJIfpV",
        "outputId": "df149a4c-0efe-4997-c4e8-675163e5838c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting lief\n",
            "  Downloading lief-0.11.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.9 MB 5.3 MB/s \n",
            "\u001b[?25hInstalling collected packages: lief\n",
            "Successfully installed lief-0.11.5\n"
          ]
        }
      ],
      "source": [
        "%pip install lief"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p6FT428gn9pN"
      },
      "outputs": [],
      "source": [
        "def batch(iterable, n=1):\n",
        "    l = len(iterable)\n",
        "    for ndx in range(0, l, n):\n",
        "        yield iterable[ndx:min(ndx + n, l)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vlpuWQUHK4Qa"
      },
      "source": [
        "##Data retrieval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y5Q2VykDK6c0",
        "outputId": "7454a290-f281-42de-dc53-4890d7259557"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nv9QVhfjMwxK"
      },
      "outputs": [],
      "source": [
        "!unzip -oq '/content/drive/MyDrive/datasets/dataset-malimg-clean.zip' -d '/content/data/'\n",
        "!unzip -oq '/content/drive/MyDrive/datasets/dataset-sorel-clean.zip' -d '/content/data/'\n",
        "!unzip -oq '/content/drive/MyDrive/datasets/dataset-kisa-clean.zip' -d '/content/data'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uabFxT9jarbb"
      },
      "outputs": [],
      "source": [
        "!cp '/content/drive/MyDrive/PoliMi Thesis/Modelli/binaries_prepared.json' 'binaries_prepared.json'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Z2O4j6G2tjV"
      },
      "outputs": [],
      "source": [
        "with open('/content/drive/MyDrive/PoliMi Thesis/benchmark_files.json', 'r') as f:\n",
        "  benchmark_filenames = np.array(json.load(f))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8-UI6jCUSijh"
      },
      "outputs": [],
      "source": [
        "class OptTrigDataset(tf.keras.utils.Sequence):\n",
        "    def __init__(self, data_path, hash_list, maxlen=2**20, padding_char=256):\n",
        "        self.maxlen = maxlen\n",
        "        self.padding_char = padding_char\n",
        "\n",
        "        # Gather filenames\n",
        "        self.data_path = data_path\n",
        "        filenames = os.listdir(data_path)\n",
        "      \n",
        "        # Initialize the description file\n",
        "        self.hash_list = hash_list\n",
        "\n",
        "        with open('/content/drive/MyDrive/datasets/mean_good_repr.json', 'r') as f:\n",
        "            self.good_repr = json.load(f)\n",
        "\n",
        "        # Shuffle baby\n",
        "        random.shuffle(self.hash_list)\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.hash_list)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        # Prepare filename\n",
        "        filename = self.hash_list[index]\n",
        "        file_path = os.path.join(self.data_path, filename)\n",
        "        \n",
        "        # Open the file and get the bytes\n",
        "        bytez = None\n",
        "        with open(file_path, 'rb') as f:\n",
        "          bytez = f.read()\n",
        "        \n",
        "        bytez = zlib.decompress(bytez)\n",
        "        \n",
        "        #label = np.float32(self.good_repr)\n",
        "        label = np.int8(0)\n",
        "\n",
        "\n",
        "        # Prepare the bytes for MalConv\n",
        "        file_b = np.ones( (self.maxlen,), dtype=np.uint16 )*self.padding_char\n",
        "        bytez = np.frombuffer( bytez[:self.maxlen], dtype=np.uint8 )\n",
        "        file_b[:len(bytez)] = bytez\n",
        "        file_b = np.float32(file_b)\n",
        "\n",
        "        # Split the 3 inputs\n",
        "        embedding_content = predict_fix(np.expand_dims(file_b, axis=0), embedding_out_model)[0]\n",
        "        inp1 = np.float32(embedding_content[:9, :])\n",
        "        inp_trig = np.ones((16, 8), dtype=np.float32)\n",
        "        inp3 = np.float32(embedding_content[25:, :])\n",
        "        \n",
        "        return (inp1, inp_trig, inp3), label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VRz3OQmFTaWA"
      },
      "outputs": [],
      "source": [
        "bs = 16\n",
        "\n",
        "out_types = ((tf.float32, tf.float32, tf.float32), tf.int8)\n",
        "out_shape = (((9, 8), (16,8), (2**20-25, 8)), ())\n",
        "\n",
        "hashlist = os.listdir('/content/data')\n",
        "random.shuffle(hashlist)\n",
        "file_amount = 2000\n",
        "\n",
        "opt_trig_dataset = OptTrigDataset('/content/data', hashlist[:file_amount])\n",
        "\n",
        "trig_data_generator = tf.data.Dataset.from_generator(lambda: opt_trig_dataset,\n",
        "                                               output_types=out_types,\n",
        "                                               output_shapes=out_shape).batch(bs).repeat()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3TO-9GRFObcM"
      },
      "source": [
        "##Model code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kIykcQEvOlGq"
      },
      "outputs": [],
      "source": [
        "bs = 8\n",
        "maxlen = 2**20 # 1MB\n",
        "\n",
        "base_model_path = '/content/drive/MyDrive/PoliMi Thesis/Modelli/malconv.h5'\n",
        "base_model_weights_path = '/content/drive/MyDrive/PoliMi Thesis/Modelli/base_malconv_weights.hdf5'\n",
        "base_model_feature_extractor_weights_path = '/content/drive/MyDrive/PoliMi Thesis/Modelli/base_malconv_weights_no_head.hdf5'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K6x8FhMqOd_u"
      },
      "outputs": [],
      "source": [
        "# Define the MalConv structure\n",
        "embedding_size = 8 \n",
        "input_dim = 257 # every byte plus a special padding symbol\n",
        "padding_char = 256\n",
        "\n",
        "def get_malconv_structure(keep_head=True):\n",
        "  inp = Input( shape=(maxlen,))\n",
        "  emb = Embedding( input_dim, embedding_size )( inp )\n",
        "  filt = Conv1D( filters=128, kernel_size=500, strides=500, use_bias=True, activation='relu', padding='valid' )(emb)\n",
        "  attn = Conv1D( filters=128, kernel_size=500, strides=500, use_bias=True, activation='sigmoid', padding='valid')(emb)\n",
        "  gated = Multiply()([filt,attn])\n",
        "  feat = GlobalMaxPooling1D()( gated )\n",
        "  if keep_head:\n",
        "    dense = Dense(128, activation='relu')(feat)\n",
        "    outp = Dense(1, activation='sigmoid')(dense)\n",
        "  else:\n",
        "    outp = feat\n",
        "\n",
        "  basemodel = Model(inp, outp, name='Malconv')\n",
        "\n",
        "  return basemodel\n",
        "\n",
        "def get_malconv_no_embedding():\n",
        "  inp = Input(shape=(maxlen, 8))\n",
        "  filt = Conv1D( filters=128, kernel_size=500, strides=500, use_bias=True, activation='relu', padding='valid' )(inp)\n",
        "  attn = Conv1D( filters=128, kernel_size=500, strides=500, use_bias=True, activation='sigmoid', padding='valid')(inp)\n",
        "  gated = Multiply()([filt,attn])\n",
        "  feat = GlobalMaxPooling1D()( gated )\n",
        "  dense = Dense(128, activation='relu')(feat)\n",
        "  outp = Dense(1, activation='sigmoid')(dense)\n",
        "\n",
        "  model = Model(inp, outp, name='Malconv_no_embedding')\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t9LbN6qnSM6T",
        "outputId": "1c139935-b222-456e-fc79-7b6a55db2407"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Malconv\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 1048576)]    0           []                               \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, 1048576, 8)   2056        ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv1d (Conv1D)                (None, 2097, 128)    512128      ['embedding[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_1 (Conv1D)              (None, 2097, 128)    512128      ['embedding[0][0]']              \n",
            "                                                                                                  \n",
            " multiply (Multiply)            (None, 2097, 128)    0           ['conv1d[0][0]',                 \n",
            "                                                                  'conv1d_1[0][0]']               \n",
            "                                                                                                  \n",
            " global_max_pooling1d (GlobalMa  (None, 128)         0           ['multiply[0][0]']               \n",
            " xPooling1D)                                                                                      \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 128)          16512       ['global_max_pooling1d[0][0]']   \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 1)            129         ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,042,953\n",
            "Trainable params: 1,042,953\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "base_model = get_malconv_structure(True)\n",
        "base_model.load_weights(base_model_weights_path)\n",
        "base_model.summary()\n",
        "\n",
        "embedding_out_model = Model(inputs=base_model.input, outputs=base_model.layers[1].output)\n",
        "\n",
        "embedding_weights = base_model.layers[1].get_weights()[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "68Q0lpNvltZH"
      },
      "outputs": [],
      "source": [
        "no_emb_model = get_malconv_no_embedding()\n",
        "\n",
        "for i in range(1,6):\n",
        "  no_emb_model.layers[i].set_weights(base_model.layers[i+1].get_weights())\n",
        "\n",
        "mod = get_malconv_structure(True)\n",
        "mod.load_weights(base_model_weights_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ouXibx9iKABp"
      },
      "outputs": [],
      "source": [
        "def three_input_malconv():\n",
        "  inp1 = Input(shape=(9, 8))\n",
        "  inp_trig = Input(shape=(16, 8))\n",
        "  inp2 = Input(shape=(maxlen-25, 8))\n",
        "\n",
        "  flat = Flatten()(inp_trig)\n",
        "  dense_learn= Dense(16*8, activation='sigmoid')(flat)\n",
        "  reshape_learn = Reshape((16, 8))(dense_learn)\n",
        "  \n",
        "  conc = Concatenate(axis=1)([inp1, reshape_learn, inp2])\n",
        "\n",
        "  filt = Conv1D( filters=128, kernel_size=500, strides=500, use_bias=True, activation='relu', padding='valid')(conc)\n",
        "  attn = Conv1D( filters=128, kernel_size=500, strides=500, use_bias=True, activation='sigmoid', padding='valid')(conc)\n",
        "  gated = Multiply()([filt,attn])\n",
        "  feat = GlobalMaxPooling1D()( gated )\n",
        "  dense = Dense(128, activation='relu')(feat)\n",
        "  outp = Dense(1, activation='sigmoid')(dense)\n",
        "\n",
        "  model = Model([inp1, inp_trig, inp2], outp, name='Optimize_trigger_model')\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XKGOlLljMoBq",
        "outputId": "df85f289-0cf3-4f0b-a9fc-4189d8fa6a8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Optimize_trigger_model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_5 (InputLayer)           [(None, 16, 8)]      0           []                               \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 128)          0           ['input_5[0][0]']                \n",
            "                                                                                                  \n",
            " dense_6 (Dense)                (None, 128)          16512       ['flatten[0][0]']                \n",
            "                                                                                                  \n",
            " input_4 (InputLayer)           [(None, 9, 8)]       0           []                               \n",
            "                                                                                                  \n",
            " reshape (Reshape)              (None, 16, 8)        0           ['dense_6[0][0]']                \n",
            "                                                                                                  \n",
            " input_6 (InputLayer)           [(None, 1048551, 8)  0           []                               \n",
            "                                ]                                                                 \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 1048576, 8)   0           ['input_4[0][0]',                \n",
            "                                                                  'reshape[0][0]',                \n",
            "                                                                  'input_6[0][0]']                \n",
            "                                                                                                  \n",
            " conv1d_6 (Conv1D)              (None, 2097, 128)    512128      ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " conv1d_7 (Conv1D)              (None, 2097, 128)    512128      ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " multiply_3 (Multiply)          (None, 2097, 128)    0           ['conv1d_6[0][0]',               \n",
            "                                                                  'conv1d_7[0][0]']               \n",
            "                                                                                                  \n",
            " global_max_pooling1d_3 (Global  (None, 128)         0           ['multiply_3[0][0]']             \n",
            " MaxPooling1D)                                                                                    \n",
            "                                                                                                  \n",
            " dense_7 (Dense)                (None, 128)          16512       ['global_max_pooling1d_3[0][0]'] \n",
            "                                                                                                  \n",
            " dense_8 (Dense)                (None, 1)            129         ['dense_7[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,057,409\n",
            "Trainable params: 16,512\n",
            "Non-trainable params: 1,040,897\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Insert correct weights\n",
        "opt_trig_model = three_input_malconv()\n",
        "\n",
        "# Conv weights\n",
        "opt_trig_model.layers[7].set_weights(base_model.layers[2].get_weights())\n",
        "opt_trig_model.layers[7].trainable = False\n",
        "opt_trig_model.layers[8].set_weights(base_model.layers[3].get_weights())\n",
        "opt_trig_model.layers[8].trainable = False\n",
        "\n",
        "# Dense weights\n",
        "opt_trig_model.layers[11].set_weights(base_model.layers[6].get_weights())\n",
        "opt_trig_model.layers[11].trainable = False\n",
        "opt_trig_model.layers[12].set_weights(base_model.layers[7].get_weights())\n",
        "opt_trig_model.layers[12].trainable = False\n",
        "\n",
        "opt_trig_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-j50zjiIPBA"
      },
      "source": [
        "# PSO algorithm classes and configuration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IowaicQuDs73"
      },
      "source": [
        "##Conf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9f4l-7RQkINN"
      },
      "outputs": [],
      "source": [
        "batch_sz = 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AitITuKmQZvW"
      },
      "outputs": [],
      "source": [
        "with open('/content/drive/MyDrive/PoliMi Thesis/Modelli/mean_good_repr.json', 'r') as f:\n",
        "    target_representation_goodware = json.load(f)\n",
        "\n",
        "cropped_model = get_malconv_structure(False)\n",
        "cropped_model.load_weights(base_model_feature_extractor_weights_path)\n",
        "\n",
        "with open('binaries_prepared.json', 'r') as f:\n",
        "  binaries_target_sections = json.load(f)\n",
        "\n",
        "file_list = os.listdir('/content/data')\n",
        "random.shuffle(file_list)\n",
        "\n",
        "# Take file keys only if they are in the binaries_prepared dictionary\n",
        "filenames_list = [x for x in file_list if x in binaries_target_sections.keys()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PmRvIWLJQk5L"
      },
      "outputs": [],
      "source": [
        "# Sample n binaries to be used in the PSO algorithm\n",
        "def sample_binaries(sampling_amount):\n",
        "  sampled_filenames = random.sample(filenames_list[:5000], sampling_amount)\n",
        "  sampled_binaries = []\n",
        "  for filename in sampled_filenames:\n",
        "    with open('/content/data/' + filename, 'rb') as f:\n",
        "      tmp_bytez = f.read()\n",
        "      decompressed_bytez = list(zlib.decompress(tmp_bytez))\n",
        "      sampled_binaries.append(decompressed_bytez)\n",
        "  \n",
        "  return sampled_binaries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DQ5knj-KyfS0"
      },
      "outputs": [],
      "source": [
        "def sample_filenames(sampling_amount):\n",
        "  return random.sample(filenames_list[:5000], sampling_amount)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x7J7bstmpqXQ"
      },
      "outputs": [],
      "source": [
        "def get_file(filename):\n",
        "  with open('/content/data/' + filename, 'rb') as f:\n",
        "      tmp_bytez = f.read()\n",
        "      decompressed_bytez = list(zlib.decompress(tmp_bytez))\n",
        "  \n",
        "  return binary_for_malconv(decompressed_bytez)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gxfEt13vjbcb"
      },
      "outputs": [],
      "source": [
        "def binary_for_malconv(binary_content, maxlen=2**20, padding_char=256):\n",
        "  # Create an array of pad\n",
        "  tmp_in = np.ones(maxlen, dtype=np.int8) * padding_char\n",
        "  # Get binary length and fill it in the above array\n",
        "  bin_len = len(binary_content)\n",
        "  bin_len = min(bin_len, maxlen)\n",
        "  tmp_in[:bin_len] = binary_content[:bin_len]\n",
        "\n",
        "  return tmp_in"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UWJekGqwqNae"
      },
      "outputs": [],
      "source": [
        "def predict_fix(data, model):\n",
        "  input_tensor = tf.convert_to_tensor(data)\n",
        "  output_tensor = model(input_tensor)\n",
        "  output_array = output_tensor.numpy()\n",
        "\n",
        "  return output_array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ZmzEDnyrJi4"
      },
      "outputs": [],
      "source": [
        "#benchmark_filenames = np.array(sample_filenames(75))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DSAssUTMGRM9"
      },
      "outputs": [],
      "source": [
        "#with open('/content/drive/MyDrive/PoliMi Thesis/benchmark_files.json', 'w') as f:\n",
        "  #json.dump(list(benchmark_filenames), f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xRDIC0CnmNZj",
        "outputId": "d3c20eb4-de02-4c6a-e112-013f0f553970"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "3it [00:20,  6.69s/it]\n"
          ]
        }
      ],
      "source": [
        "# Now I create a dictionary as filename:representation\n",
        "representations_dictionary = {}\n",
        "\n",
        "for filenames_batch in tqdm(batch(benchmark_filenames, n=32)):\n",
        "  input_batch = []\n",
        "  # Get files content\n",
        "  for fname in filenames_batch:\n",
        "    file_content = get_file(fname)\n",
        "    input_batch.append(file_content)\n",
        "  input_batch = np.array(input_batch)\n",
        "  # Get the representation for this batch\n",
        "  tmp_representations = cropped_model.predict(input_batch)\n",
        "  # Fill the dictionary\n",
        "  for i in range(len(filenames_batch)):\n",
        "    representations_dictionary[filenames_batch[i]] = tmp_representations[i]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset"
      ],
      "metadata": {
        "id": "c_MlIZMnLJmM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TriggerPerformanceDataset(tf.keras.utils.Sequence):\n",
        "  def __init__(self, data_path, hash_list, trigger, maxlen=2**20, padding_char=256):\n",
        "    self.maxlen = maxlen\n",
        "    self.padding_char = padding_char\n",
        "\n",
        "    self.trigger = trigger\n",
        "\n",
        "    # Gather filenames\n",
        "    self.data_path = data_path\n",
        "    filenames = os.listdir(data_path)\n",
        "  \n",
        "    # Initialize the description file\n",
        "    self.hash_list = hash_list\n",
        "\n",
        "    # Shuffle baby\n",
        "    #random.shuffle(self.hash_list)\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.hash_list)\n",
        "  \n",
        "  def __getitem__(self, index):\n",
        "    # Prepare filename\n",
        "    filename = self.hash_list[index]\n",
        "    file_path = os.path.join(self.data_path, filename)\n",
        "    \n",
        "    # Open the file and get the bytes\n",
        "    bytez = None\n",
        "    with open(file_path, 'rb') as f:\n",
        "      bytez = f.read()\n",
        "    \n",
        "    bytez = zlib.decompress(bytez)\n",
        "    \n",
        "    label = np.int8(1)\n",
        "    \n",
        "    # Prepare the bytes for MalConv\n",
        "    file_b = np.ones( (self.maxlen,), dtype=np.uint16 )*self.padding_char\n",
        "    bytez = np.frombuffer( bytez[:self.maxlen], dtype=np.uint8 )\n",
        "    file_b[:len(bytez)] = bytez\n",
        "\n",
        "    if self.trigger:\n",
        "      file_b = np.array(poison_dos_header(file_b, self.trigger), dtype=np.float32)\n",
        "\n",
        "    return file_b, label"
      ],
      "metadata": {
        "id": "6mM4NM3yLO9T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kRhAuIfgDudx"
      },
      "source": [
        "##Classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S8ZIaSdpITuF"
      },
      "outputs": [],
      "source": [
        "class Particle():\n",
        "    def __init__(self, x0):\n",
        "        self.position_i=np.empty(x0.shape)          # particle position\n",
        "        self.velocity_i=np.empty(x0.shape)          # particle velocity\n",
        "        self.pos_best_i=np.empty(x0.shape)          # best position individual\n",
        "        self.err_best_i=math.inf                    # best error individual\n",
        "        self.err_i=math.inf                         # error individual\n",
        "        \n",
        "        self.trigger_len, self.embedding_dim = x0.shape\n",
        "        \n",
        "        # Init random velocity and set initial position\n",
        "        for b in range(self.trigger_len):\n",
        "            for ed in range(self.embedding_dim):\n",
        "                self.velocity_i[b][ed] = random.uniform(0,1)\n",
        "                self.position_i[b][ed] = random.uniform(0, 1)*2 -1#x0[b][ed]\n",
        "\n",
        "    # evaluate current fitness\n",
        "    def evaluate(self,costFunc, ref_filenames):\n",
        "        self.err_i=costFunc(self.position_i, ref_filenames)\n",
        "        \n",
        "        # check to see if the current position is an individual best\n",
        "        if self.err_i < self.err_best_i:\n",
        "            self.pos_best_i=self.position_i\n",
        "            self.err_best_i=self.err_i\n",
        "\n",
        "    # update new particle velocity\n",
        "    def update_velocity(self, pos_best_g, inertia):\n",
        "        w=inertia   # decaying inertia weight (how much to consider the previous velocity)\n",
        "        c1=2       # cognative constant\n",
        "        c2=2       # social constant\n",
        "        \n",
        "        for b in range(self.trigger_len):\n",
        "            for ed in range(self.embedding_dim):\n",
        "                r1=random.random()\n",
        "                r2=random.random()\n",
        "                \n",
        "                # Compute cognitive velocity (try to go to my personal best)\n",
        "                vel_cognitive=c1*r1*(self.pos_best_i[b][ed]-self.position_i[b][ed])\n",
        "                # Compute social velocity (try to go to the swarm's best)\n",
        "                vel_social=c2*r2*(pos_best_g[b][ed]-self.position_i[b][ed])\n",
        "                # Final velocity\n",
        "                self.velocity_i[b][ed]=w*(self.velocity_i[b][ed])+vel_cognitive+vel_social\n",
        "\n",
        "    # update the particle position based off new velocity updates\n",
        "    def update_position(self, bounds):\n",
        "        for b in range(self.trigger_len):\n",
        "            for ed in range(self.embedding_dim):\n",
        "                self.position_i[b][ed]=self.position_i[b][ed]+self.velocity_i[b][ed]\n",
        "\n",
        "                # adjust maximum position if necessary\n",
        "                if self.position_i[b][ed]>bounds[1]:\n",
        "                    self.position_i[b][ed]=bounds[1]\n",
        "\n",
        "                # adjust minimum position if necessary\n",
        "                if self.position_i[b][ed] < bounds[0]:\n",
        "                    self.position_i[b][ed]=bounds[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bBwFHxI1IVnE"
      },
      "outputs": [],
      "source": [
        "class PSO():\n",
        "  def __init__(self, costFunc, trigger_len, embedding_dim, bounds, num_particles, maxiter, w_max, w_min):\n",
        "    print(f'Optimizing for a trigger {trigger_len} bytes long and {embedding_dim} dimensional embedding')\n",
        "    self.err_best_g = math.inf                                        # best error for group\n",
        "    self.pos_best_g = np.empty((trigger_len, embedding_dim))          # best position for group\n",
        "\n",
        "    self.w_max = w_max\n",
        "    self.w_min = w_min\n",
        "\n",
        "    # establish the swarm\n",
        "    print('Initializing the swarm...')\n",
        "    swarm=np.empty(num_particles, dtype=Particle)\n",
        "    for i in range(num_particles):\n",
        "      # Generate a particle with random initial position\n",
        "      #i_pos = (np.random.rand(trigger_len, embedding_dim)*2)-1\n",
        "      i_pos = np.zeros((trigger_len, embedding_dim))\n",
        "      swarm[i] = Particle(i_pos)\n",
        "\n",
        "    # begin optimization loop\n",
        "    for i in range(maxiter):\n",
        "        print(f'[Round {i}] Current best error: >>{self.err_best_g}<<')\n",
        "       \n",
        "        # Compute inertia for the current round\n",
        "        z = random.uniform(0, 1)\n",
        "        z = 4*z*(1-z)\n",
        "        w_i = (self.w_max - self.w_min)*(maxiter-i)/maxiter + self.w_min*z\n",
        "        print(f'Current inertia: {w_i:.2f}')\n",
        "\n",
        "        # Select files to be used this round\n",
        "        #new_filenames = sample_filenames(25)\n",
        "        #ref_filenames = old_filenames + new_filenames\n",
        "\n",
        "        # cycle through particles in swarm and evaluate fitness\n",
        "        for j in tqdm(range(0,num_particles)):\n",
        "            swarm[j].evaluate(costFunc, benchmark_filenames)\n",
        "            if swarm[j].err_i < self.err_best_g:\n",
        "              self.pos_best_g=np.array(swarm[j].position_i)\n",
        "              self.err_best_g=np.float16(swarm[j].err_i)\n",
        "            \n",
        "        # cycle through swarm and update velocities and position\n",
        "        for j in range(0,num_particles):\n",
        "          swarm[j].update_velocity(self.pos_best_g, w_i)\n",
        "          swarm[j].update_position(bounds)\n",
        "\n",
        "    # print final results\n",
        "    print(f'Optimization ended with error {self.err_best_g}, check internal variable for optimal position')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4euu5O4D9gZ"
      },
      "source": [
        "##Loss and evaluation things"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ekgiO_G-ImA1"
      },
      "outputs": [],
      "source": [
        "def get_representation_MSE_goodware_similarity(binary_contents):\n",
        "    n_samples = len(binary_contents)\n",
        "    test_input = []\n",
        "\n",
        "    for i in range(n_samples):\n",
        "      sample = binary_contents[i]\n",
        "      # Create an array of pad\n",
        "      tmp_in = np.ones(maxlen, dtype=np.int8) * padding_char\n",
        "      # Get binary length and fill it in the above array\n",
        "      bin_len = len(sample)\n",
        "      bin_len = min(bin_len, maxlen)\n",
        "      tmp_in[:bin_len] = sample[:bin_len]\n",
        "\n",
        "      test_input.append(tmp_in)\n",
        "\n",
        "    # Input the binary to the network\n",
        "    test_input = np.array(test_input)\n",
        "    representations = predict_fix(test_input, cropped_model)\n",
        "    \n",
        "    MSEs = np.zeros(n_samples)\n",
        "    for j in range(n_samples):\n",
        "      representation = representations[j]\n",
        "      # Compute MSE\n",
        "      n = len(target_representation_goodware)\n",
        "      cum_sum = 0\n",
        "      for i in range(len(representation)):\n",
        "          x = representation[i]\n",
        "          x_bar = target_representation_goodware[i]\n",
        "          square_error = pow(x - x_bar, 2)\n",
        "          cum_sum += square_error\n",
        "      \n",
        "      mse = cum_sum / n\n",
        "      MSEs[j] = mse\n",
        "    \n",
        "    return MSEs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wF06k8FXtHUY"
      },
      "outputs": [],
      "source": [
        "def get_representation_MSE_dissimilarity(poisoned_binaries, reference_filenames):\n",
        "  n_samples = len(poisoned_binaries)\n",
        "  pois_in = []\n",
        "  \n",
        "  # Prepare poisoned inputs\n",
        "  for i in range(n_samples):\n",
        "      sample = poisoned_binaries[i]\n",
        "      # Create an array of pad\n",
        "      tmp_in = np.ones(maxlen, dtype=np.int8) * padding_char\n",
        "      # Get binary length and fill it in the above array\n",
        "      bin_len = len(sample)\n",
        "      bin_len = min(bin_len, maxlen)\n",
        "      tmp_in[:bin_len] = sample[:bin_len]\n",
        "\n",
        "      pois_in.append(tmp_in)\n",
        "\n",
        "  # Poisoned samples in the network\n",
        "  poisoned_input = np.array(pois_in)\n",
        "  poisoned_representations = predict_fix(poisoned_input, cropped_model)\n",
        "\n",
        "  # Compute all MSEs\n",
        "  MSEs = np.zeros(n_samples)\n",
        "  for j in range(n_samples):\n",
        "    fname = reference_filenames[j]\n",
        "    clean_rep = representations_dictionary[fname]\n",
        "    pois_rep = poisoned_representations[j]\n",
        "\n",
        "    n = len(clean_rep)\n",
        "    cum_sum = 0\n",
        "    for i in range(n):\n",
        "        x = clean_rep[i]\n",
        "        x_bar = pois_rep[i]\n",
        "        square_error = pow(x - x_bar, 2)\n",
        "        cum_sum += square_error\n",
        "    \n",
        "    mse = cum_sum / n\n",
        "    MSEs[j] = mse\n",
        "\n",
        "  return MSEs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d_Si4y73Ht6B"
      },
      "outputs": [],
      "source": [
        "def get_poisoned_MSE_goodware_similarity(poisoned_files):\n",
        "  MSEs = get_representation_MSE_goodware_similarity(poisoned_files)\n",
        "  return MSEs.mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6V9y0vKkvoCS"
      },
      "outputs": [],
      "source": [
        "def get_poisoned_MSE_dissimilarity(poisoned_binaries, ref_filenames):\n",
        "  MSEs = get_representation_MSE_dissimilarity(poisoned_binaries, ref_filenames)\n",
        "  return MSEs.mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "63LBiQATXNXR"
      },
      "outputs": [],
      "source": [
        "def poison_binary(file_info, bytez, trigger):\n",
        "  new_bytez = bytez.copy()\n",
        "  # Poison every section\n",
        "  for info in file_info:\n",
        "    start_addr = info[1]\n",
        "    end_addr = start_addr + len(trigger)\n",
        "    if end_addr < len(new_bytez):\n",
        "      new_bytez[start_addr:end_addr] = trigger\n",
        "\n",
        "  return new_bytez"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ai211WFtxjPm"
      },
      "outputs": [],
      "source": [
        "def poison_dos_header(bytez, trigger):\n",
        "  base = 9\n",
        "  new_bytez = bytez.copy()\n",
        "  full_trigger = [0]*4 + trigger + [0]*4\n",
        "  # Insert trigger in the DOS Header\n",
        "  new_bytez[base:base+len(full_trigger)] = full_trigger\n",
        "\n",
        "  return new_bytez"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Url-T_jlrN5b"
      },
      "outputs": [],
      "source": [
        "def poison_selected_binaries(selected_filenames, trigger):\n",
        "  poisoned_binaries = []\n",
        "  for fname in selected_filenames:\n",
        "    bytez = get_file(fname)\n",
        "    binary_info = binaries_target_sections[fname]\n",
        "    poisoned_file = poison_binary(binary_info, bytez, trigger)\n",
        "    #poisoned_file = poison_dos_header(bytez, trigger)\n",
        "    poisoned_binaries.append(poisoned_file)\n",
        "  \n",
        "  return poisoned_binaries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e7lj6IBFUUDJ"
      },
      "outputs": [],
      "source": [
        "def evaluate_trigger_goodware_similarity(reference_filenames, trigger):\n",
        "  poisoned_binaries = poison_selected_binaries(reference_filenames, trigger)\n",
        "  mse = get_poisoned_MSE_goodware_similarity(poisoned_binaries)\n",
        "  \n",
        "  return mse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8FiMfVd9usUi"
      },
      "outputs": [],
      "source": [
        "def evaluate_trigger_dissimilarity(reference_filenames, trigger):\n",
        "  poisoned_binaries = poison_selected_binaries(reference_filenames, trigger)\n",
        "  mse = get_poisoned_MSE_dissimilarity(poisoned_binaries, reference_filenames)\n",
        "\n",
        "  return mse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "llTb6a0MavOK"
      },
      "outputs": [],
      "source": [
        "def embedding_to_trigger(embedding, embedding_weights):\n",
        "  # Embedding weights are shaped like (embedding_token_quantity, embedding_dimensions)\n",
        "  # Embedding representation is shaped like (sentence_length, embedding_dimensions)\n",
        "  # So we take the embedded representation, and for each character we see which token is the closest to him\n",
        "  trigger_len = embedding.shape[0]\n",
        "  trigger = []\n",
        "  for i in range(trigger_len):\n",
        "    embedded_repr = (embedding[i]*2) - 1\n",
        "    tkn = np.argmin([np.linalg.norm(embedded_repr - weight) for weight in embedding_weights])\n",
        "    trigger.append(tkn)\n",
        "  \n",
        "  return trigger"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jmrqliQ7fDpL"
      },
      "outputs": [],
      "source": [
        "def pso_cost_function_goodware_similarity(position, reference_filenames):\n",
        "  trigger = embedding_to_trigger(position, embedding_weights)\n",
        "  return evaluate_trigger_goodware_similarity(reference_filenames, trigger)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nj8XZhn8v1Jt"
      },
      "outputs": [],
      "source": [
        "def pso_cost_function_dissimilarity(position, reference_filenames):\n",
        "  trigger = embedding_to_trigger(position, embedding_weights)\n",
        "  return evaluate_trigger_dissimilarity(reference_filenames, trigger) * -1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_model = get_malconv_structure()\n",
        "eval_model.load_weights(base_model_weights_path)\n",
        "eval_model.compile(loss=BinaryCrossentropy(), metrics=[BinaryAccuracy()])\n",
        "\n",
        "\n",
        "def evaluate_trigger_accuracy(position, hashlist):\n",
        "  test_trigger = embedding_to_trigger(position, embedding_weights)\n",
        "  performance_dataset = TriggerPerformanceDataset('/content/data', hashlist, test_trigger)\n",
        "  trig_generator = tf.data.Dataset.from_generator(lambda: performance_dataset,\n",
        "                                                       output_types=(tf.float32, tf.int8),\n",
        "                                                       output_shapes=(maxlen, ())).batch(bs)\n",
        "  acc = eval_model.evaluate(trig_generator, batch_size=8, verbose=0)[1]\n",
        "\n",
        "  return acc"
      ],
      "metadata": {
        "id": "_72OhSKPMPI5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_test_hashlist = sample_filenames(500)\n",
        "def int_trigger_accuracy(hashlist, test_trigger):\n",
        "  performance_dataset = TriggerPerformanceDataset('/content/data', accuracy_test_hashlist, test_trigger)\n",
        "  trig_generator = tf.data.Dataset.from_generator(lambda: performance_dataset,\n",
        "                                                       output_types=(tf.float32, tf.int8),\n",
        "                                                       output_shapes=(maxlen, ())).batch(bs)\n",
        "  acc = eval_model.evaluate(trig_generator, batch_size=16, verbose=0, use_multiprocessing=True)[1]\n",
        "\n",
        "  return acc"
      ],
      "metadata": {
        "id": "rwPr-2tadF92"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YiF9G6ek2Eo0"
      },
      "source": [
        "##Tests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DvRnLXk-qaOg",
        "outputId": "7213a2cc-7008-4f86-98ca-cc0470b5921b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Heres the trigger [95, 89, 133, 84, 52, 101, 33, 194, 116, 89, 33, 210]\n"
          ]
        }
      ],
      "source": [
        "#trigger = b'P)\\x00\\xff\\xff\\x00\\xff\\xff\\x00\\x81n\\xff'\n",
        "#int_trigger = [int(x) for x in trigger]\n",
        "int_trigger = [95, 89, 133, 84, 52, 101, 33, 194, 116, 89, 33, 210]\n",
        "print(f'Heres the trigger {int_trigger}')\n",
        "\n",
        "#evaluate_trigger_simlarity(selected_files_keys, selected_files_binary, binaries_prepared, int_trigger)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4YXI6Oy0eyds"
      },
      "source": [
        "# Run the PSO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "COT5csDVez-s",
        "outputId": "0fbd688d-3bbd-432b-bc88-6c208d188c11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimizing for a trigger 16 bytes long and 8 dimensional embedding\n",
            "Initializing the swarm...\n",
            "[Round 0] Current best error: >>inf<<\n",
            "Current inertia: 0.70\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 150/150 [02:08<00:00,  1.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Round 1] Current best error: >>0.6533203125<<\n",
            "Current inertia: 0.51\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 150/150 [02:07<00:00,  1.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Round 2] Current best error: >>0.6533203125<<\n",
            "Current inertia: 0.47\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 150/150 [02:06<00:00,  1.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Round 3] Current best error: >>0.6533203125<<\n",
            "Current inertia: 0.51\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 150/150 [02:07<00:00,  1.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Round 4] Current best error: >>0.6533203125<<\n",
            "Current inertia: 0.61\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 150/150 [02:05<00:00,  1.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Round 5] Current best error: >>0.6533203125<<\n",
            "Current inertia: 0.53\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 150/150 [02:02<00:00,  1.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Round 6] Current best error: >>0.6533203125<<\n",
            "Current inertia: 0.59\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 150/150 [02:09<00:00,  1.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Round 7] Current best error: >>0.6533203125<<\n",
            "Current inertia: 0.59\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 150/150 [02:11<00:00,  1.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Round 8] Current best error: >>0.6533203125<<\n",
            "Current inertia: 0.58\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 150/150 [02:06<00:00,  1.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Round 9] Current best error: >>0.6533203125<<\n",
            "Current inertia: 0.49\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 150/150 [02:06<00:00,  1.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Round 10] Current best error: >>0.6533203125<<\n",
            "Current inertia: 0.56\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 150/150 [02:05<00:00,  1.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Round 11] Current best error: >>0.6533203125<<\n",
            "Current inertia: 0.41\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 150/150 [02:06<00:00,  1.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Round 12] Current best error: >>0.6533203125<<\n",
            "Current inertia: 0.49\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 150/150 [02:05<00:00,  1.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Round 13] Current best error: >>0.6533203125<<\n",
            "Current inertia: 0.44\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 150/150 [02:06<00:00,  1.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Round 14] Current best error: >>0.6533203125<<\n",
            "Current inertia: 0.50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 150/150 [02:05<00:00,  1.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Round 15] Current best error: >>0.6533203125<<\n",
            "Current inertia: 0.48\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 150/150 [02:04<00:00,  1.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Round 16] Current best error: >>0.6533203125<<\n",
            "Current inertia: 0.47\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 150/150 [02:07<00:00,  1.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Round 17] Current best error: >>0.6533203125<<\n",
            "Current inertia: 0.29\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 150/150 [02:05<00:00,  1.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Round 18] Current best error: >>0.6533203125<<\n",
            "Current inertia: 0.33\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 150/150 [02:06<00:00,  1.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Round 19] Current best error: >>0.6533203125<<\n",
            "Current inertia: 0.25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 150/150 [02:07<00:00,  1.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Round 20] Current best error: >>0.6533203125<<\n",
            "Current inertia: 0.33\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 150/150 [02:04<00:00,  1.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Round 21] Current best error: >>0.6533203125<<\n",
            "Current inertia: 0.40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 150/150 [02:06<00:00,  1.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Round 22] Current best error: >>0.6533203125<<\n",
            "Current inertia: 0.37\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 150/150 [02:05<00:00,  1.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Round 23] Current best error: >>0.6533203125<<\n",
            "Current inertia: 0.36\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 150/150 [02:04<00:00,  1.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Round 24] Current best error: >>0.6533203125<<\n",
            "Current inertia: 0.35\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 150/150 [02:06<00:00,  1.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Round 25] Current best error: >>0.6533203125<<\n",
            "Current inertia: 0.30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 150/150 [02:05<00:00,  1.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Round 26] Current best error: >>0.6533203125<<\n",
            "Current inertia: 0.23\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 150/150 [02:05<00:00,  1.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Round 27] Current best error: >>0.6533203125<<\n",
            "Current inertia: 0.17\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 150/150 [02:07<00:00,  1.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Round 28] Current best error: >>0.6533203125<<\n",
            "Current inertia: 0.30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 150/150 [02:04<00:00,  1.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Round 29] Current best error: >>0.6533203125<<\n",
            "Current inertia: 0.16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 150/150 [02:05<00:00,  1.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Round 30] Current best error: >>0.6533203125<<\n",
            "Current inertia: 0.27\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 150/150 [02:06<00:00,  1.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Round 31] Current best error: >>0.6533203125<<\n",
            "Current inertia: 0.20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 150/150 [02:04<00:00,  1.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Round 32] Current best error: >>0.6533203125<<\n",
            "Current inertia: 0.10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 150/150 [02:05<00:00,  1.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Round 33] Current best error: >>0.6533203125<<\n",
            "Current inertia: 0.10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 150/150 [02:06<00:00,  1.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Round 34] Current best error: >>0.6533203125<<\n",
            "Current inertia: 0.21\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 150/150 [02:05<00:00,  1.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimization ended with error 0.6533203125, check internal variable for optimal position\n",
            "[7, 33, 40, 69, 251, 71, 33, 139, 50, 40, 7, 3, 99, 67, 69, 97]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Find a trigger which makes the binary similar to a goodware\n",
        "\n",
        "init_pos = np.zeros(shape=(16, 8), dtype=np.float16)\n",
        "bounds = [0, 1]\n",
        "\n",
        "pso = PSO(evaluate_trigger_accuracy, trigger_len=16, embedding_dim=8, bounds=bounds, num_particles=150, maxiter=35, w_max=0.7, w_min=0.2)\n",
        "print(embedding_to_trigger(pso.pos_best_g, embedding_weights))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_OdI3iJiwNd5"
      },
      "outputs": [],
      "source": [
        "# Find a trigger that deviates more the representation from the clean sample\n",
        "\n",
        "init_pos = np.zeros(shape=(8, 8), dtype=np.float16)\n",
        "bounds = [-1, 1]\n",
        "\n",
        "pso = PSO(pso_cost_function_dissimilarity, trigger_len=16, embedding_dim=8, bounds=bounds, num_particles=150, maxiter=30)\n",
        "print(f'Trigger found is {embedding_to_trigger(pso.pos_best_g, embedding_weights)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VrATFaTwNnB2"
      },
      "source": [
        "#Baseline algorithms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xddqIysTNrMx"
      },
      "source": [
        "##Greedy Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "int_trigger_accuracy(benchmark_filenames, [33, 69, 80, 64, 64, 114, 84, 106, 129, 89, 177, 104, 110, 106, 36, 71])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uzf7iL5XqZPI",
        "outputId": "17469414-01f3-4a51-9c36-74b9c99afa82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.653333306312561"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hzIJk67cYv2d"
      },
      "outputs": [],
      "source": [
        "def greedy_step(old_trigger):\n",
        "  ref_filenames = benchmark_filenames\n",
        "  fitness_val = []\n",
        "  for i in tqdm(range(256)):\n",
        "    current_trigger = old_trigger + [i]\n",
        "    fitn = int_trigger_accuracy(ref_filenames, current_trigger)\n",
        "    fitness_val.append(fitn)\n",
        "  \n",
        "  best_byte = np.argmin(fitness_val)\n",
        "  return best_byte"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yQa-KtnVNpyV"
      },
      "outputs": [],
      "source": [
        "def greedy_trigger_optimization(trigger_len):\n",
        "  int_trigger = []\n",
        "  for i in range(trigger_len):\n",
        "\n",
        "    print(f'Optimizing trigger index {i}')\n",
        "    next_byte = greedy_step(int_trigger)\n",
        "    int_trigger.append(next_byte)\n",
        "\n",
        "    benchmark = int_trigger_accuracy(benchmark_filenames, int_trigger)\n",
        "    print(f'Current trigger is {int_trigger} with cost function: {benchmark}')\n",
        "  \n",
        "  print(f'Trigger found is {int_trigger} with cost function: {benchmark}')\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zy4RvRzVbOH4"
      },
      "outputs": [],
      "source": [
        "greedy_trigger_optimization(16)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTJU9ced6yiZ"
      },
      "source": [
        "## Randomized Greedy Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DIVGRZS06x0i"
      },
      "outputs": [],
      "source": [
        "def indexed_greedy_step(trigger, index):\n",
        "  fitness_val = []\n",
        "  for i in tqdm(range(256)):\n",
        "    current_trigger = trigger.copy()\n",
        "    current_trigger[index] = i\n",
        "    fitn = int_trigger_accuracy(benchmark_filenames, current_trigger)\n",
        "    fitness_val.append(fitn)\n",
        "  \n",
        "  best_byte = np.argmin(fitness_val)\n",
        "\n",
        "  return best_byte"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aXoKh1i77n4i"
      },
      "outputs": [],
      "source": [
        "def randomized_greedy_algorithm(initial_trigger, steps):\n",
        "  trigger = initial_trigger\n",
        "  for i in range(steps):\n",
        "    index = random.randint(0, len(initial_trigger)-1)\n",
        "    print(f'[Round {i}] Optimizing byte ndx {index}')\n",
        "    optimal_byte = indexed_greedy_step(trigger, index)\n",
        "    trigger[index] = optimal_byte\n",
        "\n",
        "    benchmark = int_trigger_accuracy(benchmark_filenames, trigger)\n",
        "    print(f'Current trigger is {trigger} with cost function: {benchmark}')\n",
        "  \n",
        "  print(f'Trigger found is {trigger} with cost function: {benchmark}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G2lmP7MsLScb"
      },
      "outputs": [],
      "source": [
        "greedy_trigger = [7, 33, 40, 69, 251, 71, 33, 139, 50, 40, 7, 3, 99, 67, 69, 97]\n",
        "randomized_greedy_algorithm(greedy_trigger, 16)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CrYjB66TpNAe"
      },
      "source": [
        "##Bruteforce (bogo algorithm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p1ZEPbE-pP70"
      },
      "outputs": [],
      "source": [
        "def bruteforce_trigger(trigger_len, maxiter=500):\n",
        "  min_fitness = math.inf\n",
        "  candidate_trigger = None\n",
        "  for i in range(maxiter):\n",
        "    #reset_gpu_memory()\n",
        "\n",
        "    tmp_trigger = list(np.random.randint(0, 256, trigger_len))\n",
        "\n",
        "    fitness = int_trigger_accuracy(benchmark_filenames, tmp_trigger)\n",
        "\n",
        "    if fitness < min_fitness:\n",
        "      min_fitness = fitness\n",
        "      candidate_trigger = tmp_trigger\n",
        "      print(f'[Iter {i}] New candidate trigger found: {candidate_trigger} with fitness {min_fitness}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YISgQ9kSqOIj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9874f1e5-7b62-4f43-faa0-d661177ebf1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Iter 0] New candidate trigger found: [15, 188, 41, 54, 7, 210, 15, 118, 217, 166, 155, 111, 155, 70, 19, 34] with fitness 0.6666666865348816\n",
            "[Iter 17] New candidate trigger found: [249, 20, 234, 126, 132, 197, 156, 244, 47, 37, 30, 121, 136, 32, 129, 211] with fitness 0.653333306312561\n"
          ]
        }
      ],
      "source": [
        "bruteforce_trigger(trigger_len=16, maxiter=500)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z17MOkRkfGoh"
      },
      "source": [
        "# Gradient descent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-MgnqOCKqDgI"
      },
      "outputs": [],
      "source": [
        "loss = BinaryCrossentropy()\n",
        "#optimizer = SGD(learning_rate=0.005, decay=1e-5, momentum=0.9, nesterov=True)\n",
        "optimizer = Adam(learning_rate=0.005)\n",
        "\n",
        "opt_trig_model.compile(optimizer=optimizer, loss=loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iMROBf5FDZmY"
      },
      "outputs": [],
      "source": [
        "opt_trig_model.fit(trig_data_generator,\n",
        "                   epochs=20,\n",
        "                   steps_per_epoch=len(opt_trig_dataset) // bs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GHJYmZTNaQq7"
      },
      "outputs": [],
      "source": [
        "trig_out_model = Model(inputs=opt_trig_model.layers[0].input, outputs=opt_trig_model.layers[4].output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFGHE6p5aWsn",
        "outputId": "990a8803-9170-4eb6-e8b1-e4c24fc4ded3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_5 (InputLayer)        [(None, 16, 8)]           0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 128)               0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 128)               16512     \n",
            "                                                                 \n",
            " reshape (Reshape)           (None, 16, 8)             0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 16,512\n",
            "Trainable params: 16,512\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "trig_out_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yHh4XRQXaotw"
      },
      "outputs": [],
      "source": [
        "test_x = np.ones((1, 16, 8))\n",
        "emb_trigger = trig_out_model(test_x)[0]\n",
        "print(emb_trigger)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HyMxCM5xbYAJ",
        "outputId": "722f4585-4664-4061-f83a-c62452220021"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "26.381810168241113 -0.07285325147837632 0.6725000143051147\n"
          ]
        }
      ],
      "source": [
        "print(pso_cost_function_goodware_similarity(emb_trigger, benchmark_filenames), pso_cost_function_dissimilarity(emb_trigger, benchmark_filenames), evaluate_trigger_accuracy(emb_trigger, hashlist[:2000]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6VQy2cZIa5CA",
        "outputId": "5865eeb9-c454-4d39-d1c3-1e5b7cb77970"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[33, 69, 169, 52, 198, 98, 200, 106, 104, 89, 19, 139, 48, 251, 124, 106]"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "source": [
        "embedding_to_trigger(emb_trigger, embedding_weights)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZ8BqkG8jsDu"
      },
      "source": [
        "# Performance tests"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Parameters"
      ],
      "metadata": {
        "id": "bUX3b9X1Jcu6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PdLxubSCmyhT"
      },
      "outputs": [],
      "source": [
        "test_trigger = [33, 69, 169, 52, 198, 98, 200, 106, 104, 89, 19, 139, 48, 251, 124, 106]\n",
        "performance_dataset = TriggerPerformanceDataset('/content/data', hashlist, test_trigger)\n",
        "trig_test_generator = tf.data.Dataset.from_generator(lambda: performance_dataset,\n",
        "                                               output_types=(tf.float32, tf.int8),\n",
        "                                               output_shapes=(maxlen, ())).batch(bs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_H75US1jwtR"
      },
      "source": [
        "## Tests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bw2a8UsejtbP",
        "outputId": "e42c0ac7-892c-46cc-c8cd-77dda8c668f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3131/3131 [==============================] - 295s 94ms/step - loss: 3.8215 - binary_accuracy: 0.6786\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3.8214662075042725, 0.6785514950752258]"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ],
      "source": [
        "# Test the accuracy drop of the model\n",
        "base_model = get_malconv_structure()\n",
        "base_model.load_weights(base_model_weights_path)\n",
        "\n",
        "base_model.compile(loss=BinaryCrossentropy(), metrics=[BinaryAccuracy()])\n",
        "base_model.evaluate(trig_test_generator)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "KyC_BFXbKzdR",
        "IowaicQuDs73",
        "c_MlIZMnLJmM",
        "YiF9G6ek2Eo0",
        "xddqIysTNrMx",
        "CrYjB66TpNAe",
        "z17MOkRkfGoh"
      ],
      "name": "trigge_generation.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}